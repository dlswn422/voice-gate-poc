import os
import time
from dotenv import load_dotenv

import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI


def make_speech_recognizer():
    key = os.getenv("AZURE_SPEECH_KEY")
    region = os.getenv("AZURE_SPEECH_REGION")
    lang = os.getenv("AZURE_SPEECH_LANGUAGE", "ko-KR")
    if not key or not region:
        raise RuntimeError("AZURE_SPEECH_KEY / AZURE_SPEECH_REGION ê°€ .envì— ì—†ìŠµë‹ˆë‹¤.")

    speech_config = speechsdk.SpeechConfig(subscription=key, region=region)
    speech_config.speech_recognition_language = lang

    # (ì„ íƒ) ì£¼ì°¨ì¥ ë„ë©”ì¸ íŒíŠ¸ - ì¸ì‹ í’ˆì§ˆì— ë„ì›€
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)
    phrase_list = speechsdk.PhraseListGrammar.from_recognizer(recognizer)
    for p in ["ì°¨ë‹¨ê¸°", "ê²Œì´íŠ¸", "ë¬¸", "ì¶œêµ¬", "ì…êµ¬", "ê²°ì œ", "ìš”ê¸ˆ", "ì •ê¸°ê¶Œ", "ì˜ìˆ˜ì¦", "í• ì¸", "ë¬¸ì´ ì•ˆ ì—´ë ¤ìš”", "ì°¨ë‹¨ê¸°ê°€ ì•ˆ ì—´ë ¤ìš”"]:
        phrase_list.addPhrase(p)

    return recognizer


def make_speech_synthesizer():
    key = os.getenv("AZURE_SPEECH_KEY")
    region = os.getenv("AZURE_SPEECH_REGION")
    voice = os.getenv("AZURE_SPEECH_VOICE", "ko-KR-SunHiNeural")
    if not key or not region:
        raise RuntimeError("AZURE_SPEECH_KEY / AZURE_SPEECH_REGION ê°€ .envì— ì—†ìŠµë‹ˆë‹¤.")

    speech_config = speechsdk.SpeechConfig(subscription=key, region=region)
    speech_config.speech_synthesis_voice_name = voice

    # âœ… íŒŒì¼ ì €ì¥ ì—†ì´ ìŠ¤í”¼ì»¤ë¡œ ë°”ë¡œ ì¶œë ¥
    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)
    return speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)


def make_azure_openai_client():
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "").strip().rstrip("/")
    api_key = os.getenv("AZURE_OPENAI_API_KEY", "").strip()
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "").strip()

    if not endpoint or not api_key or not api_version:
        raise RuntimeError("AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_API_KEY / AZURE_OPENAI_API_VERSION ëˆ„ë½")

    return AzureOpenAI(
        azure_endpoint=endpoint,
        api_key=api_key,
        api_version=api_version,
    )


def llm_reply(client: AzureOpenAI, deployment: str, history: list[dict], user_text: str) -> str:
    messages = history + [{"role": "user", "content": user_text}]
    resp = client.chat.completions.create(
        model=deployment,  # âœ… deployment name
        messages=messages,
        temperature=0.3,
        max_tokens=220,
    )
    return (resp.choices[0].message.content or "").strip()


def main():
    load_dotenv()

    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "").strip()
    if not deployment:
        raise RuntimeError("AZURE_OPENAI_DEPLOYMENT(ë°°í¬ ì´ë¦„)ì´ .envì— ì—†ìŠµë‹ˆë‹¤.")

    recognizer = make_speech_recognizer()
    synthesizer = make_speech_synthesizer()
    client = make_azure_openai_client()

    # ìµœì†Œ ìƒë‹´ í†¤
    history: list[dict] = [{
        "role": "system",
        "content": (
            "ë„ˆëŠ” ì£¼ì°¨ì¥ ê³ ê°ìƒë‹´ AIë‹¤. í•œêµ­ì–´ë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ ì•ˆë‚´í•œë‹¤. "
            "í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ í•œ ë²ˆì— 1ê°œë§Œ ì§ˆë¬¸í•œë‹¤. "
            "ë‹µë³€ì€ 1~2ë¬¸ì¥ìœ¼ë¡œ, ë„ˆë¬´ ê¸¸ê²Œ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤."
            "ê·œì¹™: ì…ë ¥ ë¬¸ì¥ì˜ ë¬¸ì¥ë¶€í˜¸(?, !)ëŠ” ìŒì„± ì¸ì‹ ìë™ ë³´ì • ê²°ê³¼ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ë„ í•´ì„ ì‹œ ê³¼ë„í•˜ê²Œ ë°˜ì˜í•˜ì§€ ë§ˆë¼. "
            "ì¶”ê°€ ê·œì¹™: ë„ˆì˜ ì—­í• ì€ 'ì£¼ì°¨ì¥/ì°¨ëŸ‰ ì¶œì…/ê²°ì œ/ìš”ê¸ˆ/ì°¨ë‹¨ê¸°/ì •ê¸°ê¶Œ/ë“±ë¡/ì‹œì„¤ ê³ ì¥' ê´€ë ¨ ìƒë‹´ë§Œ í•œë‹¤. "
            "ì‚¬ìš©ì ë°œí™”ê°€ ì£¼ì°¨ì¥ ìš´ì˜ê³¼ ë¬´ê´€í•œ ì¼ë°˜ ì§€ì‹(ì˜ë£Œ/ë³‘ì›/ë²•ë¥ /íˆ¬ì/ì—°ì• /ì •ì¹˜ ë“±)ìœ¼ë¡œ í•´ì„ë  ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©´, "
            "ê·¸ ë°©í–¥ìœ¼ë¡œ ì ˆëŒ€ ë‹µí•˜ì§€ ë§ê³  'ì£¼ì°¨ì¥ ë¬¸ì˜ì¸ì§€'ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ í™•ì¸ ì§ˆë¬¸ì„ í•´ë¼. "
            "ì˜ˆ: 'ì†ŒìŒ' ê°™ì€ ë‹¨ì–´ëŠ” ë³‘ì›/ì˜ë£Œë¡œ ì—°ê²°í•˜ì§€ ë§ê³ , 'ì°¨ë‹¨ê¸°/ê¸°ê¸°/ê²½ê³ ìŒ/ì•ˆë‚´ë°©ì†¡ ì†Œë¦¬' ê°™ì€ ì£¼ì°¨ì¥ ìƒí™©ìœ¼ë¡œ ë¨¼ì € ì¬í•´ì„í•œë‹¤. "
            "ê·¸ë˜ë„ ì£¼ì°¨ì¥ê³¼ ë¬´ê´€í•˜ë©´: 'ì£¼ì°¨ì¥ ì´ìš© ê´€ë ¨ ë¬¸ì˜ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì–´ë–¤ ì£¼ì°¨ì¥ ë¬¸ì œì´ì‹ ê°€ìš”?' ë¼ê³  ë‹µí•œë‹¤."
        )
    }]

    print("ğŸ¤ ë§í•˜ë©´ STT â†’ LLM â†’ TTSë¡œ ì‘ë‹µí•©ë‹ˆë‹¤. (ì¢…ë£Œ: 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ê¸°)")
    synthesizer.speak_text_async("ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?").get()

    while True:
        print("\n[LISTEN] ë§ì”€í•˜ì„¸ìš”...")
        stt = recognizer.recognize_once_async().get()

        if stt.reason != speechsdk.ResultReason.RecognizedSpeech or not stt.text:
            print("[STT] ì¸ì‹ ì‹¤íŒ¨/ë¬´ì‘ë‹µ")
            synthesizer.speak_text_async("ì˜ ë“¤ë¦¬ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.").get()
            continue

        user_text = stt.text.strip()
        print("[USER]", user_text)

        if "ì¢…ë£Œ" in user_text:
            synthesizer.speak_text_async("í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.").get()
            break

        try:
            answer = llm_reply(client, deployment, history, user_text)
        except Exception as e:
            print("[LLM ERROR]", repr(e))
            synthesizer.speak_text_async("ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.").get()
            continue

        if not answer:
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”."

        print("[AI]", answer)

        history.append({"role": "user", "content": user_text})
        history.append({"role": "assistant", "content": answer})

        synthesizer.speak_text_async(answer).get()
        time.sleep(0.1)


if __name__ == "__main__":
    main()
