"use client"

import { useRef, useState } from "react"

type Status = "idle" | "listening" | "thinking" | "speaking"

const STATUS_TEXT: Record<Status, string> = {
  idle: "ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”",
  listening: "ë§ì”€ì„ ë“£ê³  ìˆì–´ìš”",
  thinking: "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”",
  speaking: "ì•ˆë‚´ë¥¼ ì‹œì‘í• ê²Œìš”"
}

const WS_BASE = "ws://127.0.0.1:8000/ws/voice"
const API_BASE = "http://127.0.0.1:8000"

export default function Home() {
  /* ===============================
     ìƒíƒœ(UI) + ìƒíƒœ Ref(ë¡œì§)
  =============================== */
  const [status, _setStatus] = useState<Status>("idle")
  const statusRef = useRef<Status>("idle")
  const setStatus = (s: Status) => {
    statusRef.current = s
    _setStatus(s)
  }

  const [botText, setBotText] = useState("")
  const [active, setActive] = useState(false)

  /* ===============================
     Refs
  =============================== */
  const wsRef = useRef<WebSocket | null>(null)
  const audioCtxRef = useRef<AudioContext | null>(null)
  const processorRef = useRef<ScriptProcessorNode | null>(null)
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null)
  const streamRef = useRef<MediaStream | null>(null)

  /* ===============================
     ğŸ¤ ë§ˆì´í¬ ì œì–´
  =============================== */
  const startMicGraph = () => {
    if (!audioCtxRef.current || !processorRef.current || !sourceRef.current) return
    sourceRef.current.connect(processorRef.current)
    processorRef.current.connect(audioCtxRef.current.destination)
  }

  const stopMicGraph = () => {
    try {
      sourceRef.current?.disconnect()
      processorRef.current?.disconnect()
    } catch {}
  }

  // ğŸ”¥ ë¬¼ë¦¬ì  ë§ˆì´í¬ OFF/ON
  const muteMicHard = () => {
    streamRef.current?.getAudioTracks().forEach(t => (t.enabled = false))
  }
  const unmuteMicHard = () => {
    streamRef.current?.getAudioTracks().forEach(t => (t.enabled = true))
  }

  /* ===============================
     â–¶ï¸ ìŒì„± ì‹œì‘
  =============================== */
  const startVoice = async () => {
    if (active) return

    setActive(true)
    setBotText("")
    setStatus("listening")

    // 1ï¸âƒ£ WebSocket
    const ws = new WebSocket(WS_BASE)
    ws.binaryType = "arraybuffer"
    wsRef.current = ws

    ws.onopen = () => console.log("[WS] connected")

    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        if (data.type === "bot_text") {
          setBotText(data.text)

          // ğŸ”´ TTS ì‹œì‘ â†’ STT ì™„ì „ ì°¨ë‹¨
          stopMicGraph()
          muteMicHard()
          setStatus("speaking")

          if (data.tts_url) {
            const audio = new Audio(
              data.tts_url.startsWith("http")
                ? data.tts_url
                : `${API_BASE}${data.tts_url}`
            )

            audio.onended = () => {
              // ğŸ”” ë°±ì—”ë“œì— TTS ì¢…ë£Œ ì•Œë¦¼ (í•µì‹¬)
              wsRef.current?.send(
                JSON.stringify({ type: "tts_end" })
              )

              // ì”í–¥ ë°©ì§€ ë”œë ˆì´ í›„ listening ë³µê·€
              setTimeout(() => {
                setStatus("listening")
                unmuteMicHard()
                startMicGraph()
              }, 400)
            }

            audio.play().catch(() => {
              wsRef.current?.send(
                JSON.stringify({ type: "tts_end" })
              )
              setStatus("listening")
              unmuteMicHard()
              startMicGraph()
            })
          } else {
            wsRef.current?.send(
              JSON.stringify({ type: "tts_end" })
            )
            setStatus("listening")
            unmuteMicHard()
            startMicGraph()
          }
        }
      } catch (e) {
        console.error("WS parse error", e)
      }
    }

    ws.onclose = () => stopVoice()

    // 2ï¸âƒ£ ë§ˆì´í¬
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })
    streamRef.current = stream

    const audioCtx = new AudioContext({ sampleRate: 16000 })
    audioCtxRef.current = audioCtx

    const source = audioCtx.createMediaStreamSource(stream)
    sourceRef.current = source

    const processor = audioCtx.createScriptProcessor(4096, 1, 1)
    processorRef.current = processor

    processor.onaudioprocess = (e) => {
      // ğŸ”¥ ì‹¤ì‹œê°„ ì œì–´ëŠ” ë°˜ë“œì‹œ refë¡œ
      if (statusRef.current !== "listening") return
      if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) return

      const input = e.inputBuffer.getChannelData(0)
      wsRef.current.send(input.buffer)
    }

    startMicGraph()
  }

  /* ===============================
     â¹ ì¢…ë£Œ
  =============================== */
  const stopVoice = () => {
    setActive(false)
    setStatus("idle")

    wsRef.current?.close()
    wsRef.current = null

    stopMicGraph()
    muteMicHard()
    processorRef.current = null
    sourceRef.current = null

    audioCtxRef.current?.close()
    audioCtxRef.current = null

    streamRef.current?.getTracks().forEach(t => t.stop())
    streamRef.current = null
  }

  const toggle = () => (active ? stopVoice() : startVoice())

  const ringStyle = {
    idle: "from-emerald-300 to-sky-400",
    listening: "from-sky-400 to-blue-500 animate-pulse",
    thinking: "from-amber-300 to-orange-400",
    speaking: "from-purple-400 to-pink-400 animate-pulse"
  }[status]

  return (
    <main className="min-h-screen bg-gradient-to-br from-emerald-50 via-sky-50 to-white flex flex-col items-center justify-center px-8 text-neutral-800">
      <header className="absolute top-14 text-center select-none">
        <h1 className="text-4xl font-semibold tracking-[0.28em] text-neutral-800/80">PARKING</h1>
        <p className="mt-2 text-xs tracking-[0.35em] text-neutral-400 uppercase">voice assistant</p>
      </header>

      <p className="mb-10 text-lg text-neutral-500">{STATUS_TEXT[status]}</p>

      <button
        onClick={toggle}
        className={`relative w-44 h-44 rounded-full bg-gradient-to-br ${ringStyle}
          flex items-center justify-center shadow-xl transition-all duration-300`}
      >
        <div className="w-32 h-32 bg-white rounded-full flex items-center justify-center shadow-inner">
          <span className="text-3xl font-semibold text-neutral-700">
            {active ? "STOP" : "START"}
          </span>
        </div>
      </button>

      <section className="mt-14 w-full max-w-xl space-y-5">
        {botText && (
          <div className="bg-emerald-100/70 backdrop-blur p-5 rounded-2xl shadow-sm">
            <p className="text-xs tracking-wide text-emerald-600 mb-2">SYSTEM RESPONSE</p>
            <p className="text-lg font-semibold">{botText}</p>
          </div>
        )}
      </section>

      <footer className="absolute bottom-10 text-center text-sm text-neutral-500">
        ì‹œì‘ì„ ëˆ„ë¥¸ ë’¤ ìì—°ìŠ¤ëŸ½ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”<br />
        ì¶œì°¨ Â· ìš”ê¸ˆ Â· ì •ì‚° ë¬¸ì œë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤
      </footer>
    </main>
  )
}
