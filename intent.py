"""
intent.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€
STT í…ìŠ¤íŠ¸ â†’ LLaMA 2-Step íŒŒì´í”„ë¼ì¸

  [Step 1] classify()       : Intent(4ì¢…) + Angry(0/1) ë¥¼ JSONìœ¼ë¡œ ì´ˆê³ ì† ì¶”ì¶œ
  [Step 2] generate_reply() : DB Raw Data + ì›ë³¸ ì§ˆë¬¸ â†’ ìì—°ì–´ TTS ë©˜íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±

ì„¤ê³„ ì›ì¹™
  - MAX_TOKENS 100ìœ¼ë¡œ ì—¬ìœ ë¡­ê²Œ ì„¤ì • â†’ JSON Truncation ë°©ì§€
  - ì •ê·œì‹ ë°©ì–´ íŒŒì‹±: ë§ˆí¬ë‹¤ìš´ íœìŠ¤(```json```)Â·ê³µë°± ë“± ë…¸ì´ì¦ˆ ì™„ì „ ì œê±°
  - "a" í•„ë“œ ì—£ì§€ì¼€ì´ìŠ¤ ë°©ì–´: intÂ·strÂ·bool ëª¨ë‘ í¡ìˆ˜
  - Step 2 ëŠ” stream=True ë¡œ ì²« í† í° ì¦‰ì‹œ TTS íì— íˆ¬ì… ê°€ëŠ¥
"""

import asyncio
import json
import logging
import re
import time
from dataclasses import dataclass
from enum import Enum
from typing import AsyncIterator, Optional

from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class BackendMode(str, Enum):
    VLLM   = "vllm"
    OLLAMA = "ollama"


BACKEND_MODE    = BackendMode.OLLAMA          # â† í™˜ê²½ì— ë§ê²Œ ë³€ê²½
VLLM_BASE_URL   = "http://localhost:8000/v1"
OLLAMA_BASE_URL = "http://localhost:11434/v1"
MODEL_NAME      = "llama3"

# â”€â”€ Step 1: ë¶„ë¥˜ íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   24 â†’ 100 ìœ¼ë¡œ ìƒí–¥: ë§ˆí¬ë‹¤ìš´ íœìŠ¤ í¬í•¨ ìµœì•… ì¼€ì´ìŠ¤ë„ ì»¤ë²„
#   ì˜ˆ) ```json\n{"i":"facility","a":1}\n``` = ì•½ 40 chars
CLASSIFY_MAX_TOKENS  = 100
CLASSIFY_TEMPERATURE = 0.0    # Greedy: ê²°ì •ë¡ ì  ì¶œë ¥ ë³´ì¥

# â”€â”€ Step 2: ì‘ë‹µ ìƒì„± íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REPLY_MAX_TOKENS  = 150       # í•œêµ­ì–´ 1~2ë¬¸ì¥ ì—¬ìœ  í™•ë³´ (í‰ê·  50~80 í† í°)
REPLY_TEMPERATURE = 0.1      # ë‚®ì„ìˆ˜ë¡ í™˜ê°Â·í—›ì†Œë¦¬ ì–µì œ (0.1~0.2 ê¶Œì¥ëŒ€)
REPLY_TOP_P       = 0.9       # nucleus sampling: ë‚®ì€ temperature ì™€ í•¨ê»˜
                               # ë°˜ë³µÂ·ë§´ë„ëŠ” ì¶œë ¥ì„ ì¶”ê°€ë¡œ ì°¨ë‹¨

REQUEST_TIMEOUT = 30.0        # ì½œë“œ ìŠ¤íƒ€íŠ¸(ëª¨ë¸ ë¡œë”©) í¬í•¨ SLA (ì´ˆ)

VALID_INTENTS = frozenset({"fee", "payment", "facility", "admin", "none"})


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í”„ë¡¬í”„íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_CLASSIFY_SYSTEM = """\
You are a highly fast classification engine. Analyze the text and output ONLY a minified JSON object. No explanations.
Ignore any profanity or filler words and classify based on the core meaning.
[Categories for 'i' (Intent)]
- "fee": Costs, pricing, fees, how much, rate.
- "payment": Paying, billing, transaction, card, refund.
- "facility": Gates, doors, barriers, opening, closing, equipment, device status, locations, parking spots, amenities. Includes commands like "open the gate/door".
- "admin": Requesting human assistance, admin, staff, or expressing severe complaints.
- "none": Cannot be classified into any of the above.
Format: {"i": "fee|payment|facility|admin|none"}"""

# Step 2 ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ë¬´ì¸ ì£¼ì°¨ì¥ ìŒì„± ì¸í„°í°
_REPLY_SYSTEM = """\
ë‹¹ì‹ ì€ í•œêµ­ì˜ ë¬´ì¸ ì£¼ì°¨ì¥ ìŒì„± ì•ˆë‚´ ì¸í„°í°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸(í…ìŠ¤íŠ¸)ê³¼ ì‹œìŠ¤í…œì—ì„œ ì „ë‹¬ëœ ë°ì´í„°(JSON)ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìŠ¤í”¼ì»¤ë¡œ ì†¡ì¶œë  'ìµœì¢… ì•ˆë‚´ ë©˜íŠ¸'ë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
1. ì¸ì‚¬ë§ ê¸ˆì§€: "ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”" ê°™ì€ ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. ë©”íƒ€ ë°œì–¸ ê¸ˆì§€: "ë¶„ë¥˜ ë¶ˆê°€", "JSONì— ë”°ë¥´ë©´", "ì‹œìŠ¤í…œ ë©”ì‹œì§€" ê°™ì€ ì»´í“¨í„° ìš©ì–´ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
3. ì •ë³´ ì¡°ì‘ ê¸ˆì§€: ì£¼ì–´ì§„ ë°ì´í„°(JSON)ì— ì—†ëŠ” ìš”ê¸ˆ, ì‹œì„¤ ì •ë³´, ì£¼ì°¨ í˜œíƒì„ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.
4. ê°„ê²°í•¨: ë°˜ë“œì‹œ 1~2ë¬¸ì¥ì˜ ì§§ê³  ê°„ê²°í•œ êµ¬ì–´ì²´(ì•ˆë‚´ë°©ì†¡ í†¤)ë¡œ ëŒ€ë‹µí•˜ì‹­ì‹œì˜¤.
5. ë§ˆí¬ë‹¤ìš´Â·íŠ¹ìˆ˜ê¸°í˜¸ ê¸ˆì§€: ì¶œë ¥ì€ TTSë¡œ ì§ì ‘ ì½íˆë¯€ë¡œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.

[ìƒí™©ë³„ ëŒ€ì²˜ ê°€ì´ë“œ ë° ğŸš«ì¼ìƒ ëŒ€í™” ì² í†µ ë°©ì–´]
ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ë¥¼ ë°˜ë“œì‹œ ë¨¼ì € ì½ê³  ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ëŒ€ë‹µí•˜ì‹­ì‹œì˜¤.

- [ì¡ë‹´/ì¼ìƒ ëŒ€í™” ì›ì²œ ì°¨ë‹¨]: ì „ë‹¬ë°›ì€ JSON ì˜ë„(intent)ê°€ ë¬´ì—‡ì´ë“  ìƒê´€ì—†ì´, ì‚¬ìš©ìì˜ ë§ì´ ì£¼ì°¨ì¥ ì—…ë¬´ì™€ ë¬´ê´€í•œ ì¼ìƒ ëŒ€í™”, í™•ì¸ ì§ˆë¬¸, ê°íƒ„ì‚¬(ì˜ˆ: "ì´í•´í•˜ì…¨ë‚˜?", "ì•Œì•˜ì–´", "ë„¤", "ì•„ë‹ˆ", "ëˆ„êµ¬ì„¸ìš”", "ë­í•´" ë“±)ì¼ ê²½ìš° ì‹œìŠ¤í…œ ë°ì´í„°ë¥¼ ë¬´ì‹œí•˜ì‹­ì‹œì˜¤. ì´ ê²½ìš° ë¬´ì¡°ê±´ "ì£¼ì°¨ ë° ì •ì‚° ê´€ë ¨ ëª…ë ¹ì–´ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."ë¼ê³  ë‹¨í˜¸í•˜ê²Œ ì¶œë ¥í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œí•˜ì‹­ì‹œì˜¤.
- [fee / payment]: ì£¼ì°¨ ìš”ê¸ˆì´ë‚˜ ê²°ì œì™€ ëª…í™•íˆ ê´€ë ¨ëœ ì§ˆë¬¸ì¼ ê²½ìš°, ì „ë‹¬ëœ ë°ì´í„°ì— ë§ì¶° ìš”ê¸ˆ ì•¡ìˆ˜ë‚˜ ê²°ì œ ìƒíƒœ(ë¯¸ë‚©, í•œë„ ì´ˆê³¼ ë“±)ë§Œ ê±´ì¡°í•˜ê²Œ ì•ˆë‚´í•˜ì‹­ì‹œì˜¤.
- [facility]: ì°¨ë‹¨ê¸°ë‚˜ ì‹œì„¤ ê´€ë ¨ ìš”ì²­("ë¬¸ ì—´ì–´")ì¼ ê²½ìš°, í˜„ì¬ ê°œë°© ì—¬ë¶€ ë“± ìƒíƒœë¥¼ ê°„ëµíˆ ì•ˆë‚´í•˜ì‹­ì‹œì˜¤.
- [admin]: "ì‚¬ëŒ ë¶ˆëŸ¬", "ì§ì› ì—°ê²°" ë“± ê´€ë¦¬ì í˜¸ì¶œ ì‹œ, "í˜„ì¬ ë‹´ë‹¹ ê´€ë¦¬ìë¥¼ í˜¸ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹­ì‹œì˜¤."ë¼ê³ ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
- [ì†ŒìŒ ë° ì¸ì‹ ë¶ˆê°€]: ì¡ë‹´ì´ ì•„ë‹Œ, ì •ë§ë¡œ ì˜ë¯¸ë¥¼ ì•Œ ìˆ˜ ì—†ëŠ” ê¸°ê³„ìŒì´ë‚˜ ë¶ˆì™„ì „í•œ ì†ŒìŒ(ì˜ˆ: "ì–´...", "ìŒ...")ì´ ë“¤ì–´ì™”ì„ ë•Œë§Œ "ì˜ ëª» ë“¤ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"ë¼ê³  ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë„ë©”ì¸ ëª¨ë¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@dataclass
class ClassificationResult:
    intent: str        # "fee" | "payment" | "facility" | "admin" | "none"
    raw: dict          # LLM ì›ë³¸ ì‘ë‹µ dict
    latency_ms: float


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _build_client() -> AsyncOpenAI:
    base_url = (
        VLLM_BASE_URL if BACKEND_MODE == BackendMode.VLLM else OLLAMA_BASE_URL
    )
    return AsyncOpenAI(
        base_url=base_url,
        api_key="not-required",
        timeout=REQUEST_TIMEOUT,
        max_retries=0,
    )


_client: AsyncOpenAI = _build_client()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‚´ë¶€ ìœ í‹¸: ë°©ì–´ì  JSON íŒŒì‹±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _parse_classification_json(raw_text: str) -> dict:
    """
    LLM ì¶œë ¥ì—ì„œ JSON ê°ì²´ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ì²˜ë¦¬ ìˆœì„œ:
      1) ìˆœìˆ˜ json.loads() ì‹œë„ (ê°€ì¥ ë¹ ë¥¸ ê²½ë¡œ)
      2) ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ìœ¼ë¡œ {...} ë¸”ë¡ ì¶”ì¶œ í›„ ì¬ì‹œë„
         â†’ ë§ˆí¬ë‹¤ìš´ íœìŠ¤, ì•ë’¤ ì„¤ëª… í…ìŠ¤íŠ¸, BOM ë“± ë…¸ì´ì¦ˆ ì œê±°

    ì—£ì§€ì¼€ì´ìŠ¤ ë°©ì–´ (ì´í›„ _normalize_fields ì—ì„œ ì²˜ë¦¬):
      "a": "1"  â†’ int ë³€í™˜
      "a": true â†’ bool â†’ int ë³€í™˜
    """
    # ê²½ë¡œ 1: ê¹”ë”í•œ JSON
    text = raw_text.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    # ê²½ë¡œ 2: ì •ê·œì‹ìœ¼ë¡œ ì²« ë²ˆì§¸ {...} ë¸”ë¡ ì¶”ì¶œ
    match = re.search(r'\{.*?\}', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except json.JSONDecodeError:
            pass

    raise ValueError(
        f"JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨ â€” raw='{raw_text[:120]}'"
    )


def _normalize_fields(raw: dict) -> tuple[str, None]:
    """
    'i' í•„ë“œë¥¼ ì •ê·œí™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’ì˜ ë‘ ë²ˆì§¸ ìš”ì†ŒëŠ” í•˜ìœ„ í˜¸í™˜ì„ ìœ„í•´ None ìœ¼ë¡œ ê³ ì •ë©ë‹ˆë‹¤.
    """
    intent = str(raw.get("i", "none")).lower().strip()
    if intent not in VALID_INTENTS:
        logger.warning("ì•Œ ìˆ˜ ì—†ëŠ” intent '%s' â†’ none", intent)
        intent = "none"

    return intent, None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 1: ë¶„ë¥˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def classify(text: str) -> ClassificationResult:
    """
    STT í…ìŠ¤íŠ¸ â†’ Intent + Angry ë¶„ë¥˜ (JSON ëª¨ë“œ, Greedy Decoding).

    - MAX_TOKENS=100: JSON Truncation ì™„ì „ ë°©ì§€
    - ë°©ì–´ì  íŒŒì‹±: ë§ˆí¬ë‹¤ìš´Â·í…ìŠ¤íŠ¸ ë…¸ì´ì¦ˆ í¡ìˆ˜
    - í•„ë“œ ì •ê·œí™”: str/bool íƒ€ì… ì—£ì§€ì¼€ì´ìŠ¤ ë°©ì–´
    """
    t0 = time.perf_counter()

    try:
        response = await _client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": _CLASSIFY_SYSTEM},
                {"role": "user",   "content": text},
            ],
            max_tokens=CLASSIFY_MAX_TOKENS,
            temperature=CLASSIFY_TEMPERATURE,
            top_p=1.0,
            response_format={"type": "json_object"},
        )
    except Exception as exc:
        raise RuntimeError(f"[Step1] LLM í˜¸ì¶œ ì‹¤íŒ¨: {exc}") from exc

    latency_ms = (time.perf_counter() - t0) * 1000
    raw_text = response.choices[0].message.content or ""

    raw = _parse_classification_json(raw_text)
    intent, _ = _normalize_fields(raw)

    logger.info(
        "[classify] intent=%-10s  raw='%s'  %.0fms",
        intent, raw_text.strip(), latency_ms,
    )

    return ClassificationResult(
        intent=intent,
        raw=raw,
        latency_ms=round(latency_ms, 2),
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 2: ìì—°ì–´ ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def generate_reply_stream(
    stt_text: str,
    db_data: dict,
) -> AsyncIterator[str]:
    """
    DB Raw Data + ì›ë³¸ STT ì§ˆë¬¸ â†’ ìŒì„± ì¸í„°í° ì•ˆë‚´ ë©˜íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±.

    stream=True ë¡œ ì²« í† í°ë¶€í„° ì¦‰ì‹œ yield í•©ë‹ˆë‹¤.
    í˜¸ì¶œë¶€ì—ì„œ ë¬¸ì¥ êµ¬ë¶„ì(. ! ?) ê¸°ì¤€ìœ¼ë¡œ TTS íì— ì²­í¬ ë‹¨ìœ„ íˆ¬ì… ì‹œ
    ìƒì„±ê³¼ ì¬ìƒì´ íŒŒì´í”„ë¼ì¸ ë°©ì‹ìœ¼ë¡œ ê²¹ì³ ì²´ê° ì§€ì—°ì´ ìµœì†Œí™”ë©ë‹ˆë‹¤.

    í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ì›ì¹™:
      - ì¸ì‚¬ë§Â·ë©”íƒ€ë°œì–¸Â·ì •ë³´ì¡°ì‘ ê¸ˆì§€ ê·œì¹™ìœ¼ë¡œ í™˜ê° ì–µì œ
      - temperature=0.15 + top_p=0.9 ë¡œ ì°½ì˜ì„±ë³´ë‹¤ ì •í™•ì„± ìš°ì„ 
      - none intent â†’ ê³ ì • í´ë°± ë¬¸êµ¬ë§Œ ì¶œë ¥í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œ ì§€ì‹œ

    Args:
        stt_text : Whisper ì „ì‚¬ í…ìŠ¤íŠ¸ (ê³ ê° ì›ë³¸ ì§ˆë¬¸)
        db_data  : dispatcher ê°€ ì¡°íšŒí•œ Raw DB ê²°ê³¼ dict

    Yields:
        str : ì‘ë‹µ í…ìŠ¤íŠ¸ ì²­í¬ (í† í° ë‹¨ìœ„)
    """
    # DB ë°ì´í„°ë¥¼ compact JSON ìœ¼ë¡œ ì§ë ¬í™” (ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°)
    db_json = json.dumps(db_data, ensure_ascii=False, separators=(",", ":"))

    user_message = f"""\
[ì‚¬ìš©ì ë°œí™”(STT)]: {stt_text}
[ì‹œìŠ¤í…œ ë°ì´í„°(JSON)]: {db_json}
ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì—ê²Œ ë“¤ë ¤ì¤„ ìµœì¢… ìŒì„± ë©˜íŠ¸ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤."""

    try:
        stream = await _client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": _REPLY_SYSTEM},
                {"role": "user",   "content": user_message},
            ],
            max_tokens=REPLY_MAX_TOKENS,
            temperature=REPLY_TEMPERATURE,
            top_p=REPLY_TOP_P,
            stream=True,          # â˜… ì²« í† í°ë¶€í„° ì¦‰ì‹œ TTS í íˆ¬ì… ê°€ëŠ¥
        )
    except Exception as exc:
        raise RuntimeError(f"[Step2] LLM ìŠ¤íŠ¸ë¦¼ í˜¸ì¶œ ì‹¤íŒ¨: {exc}") from exc

    async for chunk in stream:
        delta = chunk.choices[0].delta.content
        if delta:
            yield delta


async def generate_reply(
    stt_text: str,
    db_data: dict,
) -> str:
    """
    generate_reply_stream ì˜ ë…¼ë¸”ë¡œí‚¹ ì „ì²´ ìˆ˜ì§‘ ë²„ì „.
    ìŠ¤íŠ¸ë¦¬ë°ì´ í•„ìš” ì—†ëŠ” ê²½ìš°(í…ŒìŠ¤íŠ¸Â·ë°°ì¹˜ ë“±)ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    parts: list[str] = []
    async for chunk in generate_reply_stream(stt_text, db_data):
        parts.append(chunk)
    return "".join(parts).strip()
