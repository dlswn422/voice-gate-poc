"""
server.py â€” FastAPI ë˜í¼ ì„œë²„
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ê¸°ì¡´ main.py ì˜ CLI í„°ë¯¸ë„ ê¸°ëŠ¥ì„ ì›¹ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡
FastAPI + WebSocket ìœ¼ë¡œ ë˜í•‘í•©ë‹ˆë‹¤.

ê¸°ì¡´ ëª¨ë“ˆì„ **ìˆ˜ì • ì—†ì´** import ë§Œ í•˜ì—¬ ì¬í™œìš©í•©ë‹ˆë‹¤:
  - intent.py   : classify(), generate_reply_stream()
  - dispatcher.py : dispatch()
  - events/      : entry_event, exit_event
  - main.py      : KoreanMeloTTS, _kor_number, _apply_mecab_patch
  - pipeline.py  : TranscriptionResult (íƒ€ì…ë§Œ)
  - models.py    : load_all_models (VAD + Whisper ëª¨ë¸)
  - config.py    : PipelineConfig
  - audio_utils.py : StreamingDenoiser, build_resampler

ì—”ë“œí¬ì¸íŠ¸:
  WS   /ws/voice             ë¸Œë¼ìš°ì € ë§ˆì´í¬ PCM â†’ STT â†’ LLaMA â†’ TTS
  POST /api/plate/recognize   ì°¨ëŸ‰ë²ˆí˜¸ ì…ë ¥ â†’ ì…/ì¶œì°¨ ì²˜ë¦¬
  POST /api/payment/demo      ê²°ì œ ì‹œë®¬ë ˆì´ì…˜
  GET  /tts/{filename}        TTS wav íŒŒì¼ ì„œë¹™
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import io
import json
import logging
import re
import struct
import uuid
import warnings
from collections import deque
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

import numpy as np
import torch

# FastAPI
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
import uvicorn

# â”€â”€ ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸ (ìˆ˜ì • ì—†ì´ ì¬í™œìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from config import PipelineConfig
from intent import classify, generate_reply_stream
from dispatcher import dispatch
from events import entry_event, exit_event
from supabase import create_client, Client

# MeCab íŒ¨ì¹˜ (main.py ì™€ ë™ì¼)
from main import _apply_mecab_patch, KoreanMeloTTS, _kor_number

# ëª¨ë¸ ë¡œë“œ ìœ í‹¸
from models import load_all_models
from audio_utils import StreamingDenoiser, build_resampler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ê³  ì–µì œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("server")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Supabase í´ë¼ì´ì–¸íŠ¸ (main.py ì™€ ë™ì¼í•œ ì„¤ì •)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SUPABASE_URL = "https://hiuwgianxzqukemkjsxm.supabase.co"
SUPABASE_KEY = "sb_publishable_iQMpJQ084nk1BUvLT-DUEg_JOOkKHjX"
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TTS ì—”ì§„ + íŒŒì¼ ì„œë¹™ ë””ë ‰í† ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TTS_DIR = Path(__file__).parent / "tts_cache"
TTS_DIR.mkdir(exist_ok=True)

_tts_engine: Optional[KoreanMeloTTS] = None

def _tts_to_file(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ë¥¼ wav íŒŒì¼ë¡œ í•©ì„±í•˜ê³  íŒŒì¼ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if _tts_engine is None:
        logger.warning("[TTS] ì—”ì§„ ë¯¸ì´ˆê¸°í™” â€” í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜: %s", text)
        return None

    # ìˆ«ì â†’ í•œêµ­ì–´ ì½ê¸° ë³€í™˜ (main.py ì™€ ë™ì¼)
    processed = re.sub(r"[\d,]+", lambda m: _kor_number(m.group()), text)
    processed = processed.replace("  ", " ").strip()

    filename = f"{uuid.uuid4().hex}.wav"
    filepath = TTS_DIR / filename

    buf = io.BytesIO()
    _tts_engine._model.tts_to_file(
        processed, _tts_engine._spk, buf,
        speed=_tts_engine.speed, format="wav"
    )
    buf.seek(0)

    with open(filepath, "wb") as f:
        f.write(buf.read())

    return filename


# (asyncio ì´ë²¤íŠ¸ ë£¨í”„ëŠ” FastAPIê°€ ì œê³µí•˜ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œ ë¶ˆìš” â€” await ì§ì ‘ í˜¸ì¶œ)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VAD + Whisper ëª¨ë¸ ë¡œë”© (ì„œë²„ ê¸°ë™ ì‹œ 1íšŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_cfg = PipelineConfig()
_models = None
_denoiser = None
_resampler = None


def _init_models():
    """ëª¨ë¸ ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒ)"""
    global _models, _denoiser, _resampler
    logger.info("ğŸ”§ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    _models = load_all_models(_cfg)
    _denoiser = StreamingDenoiser(
        df_model=_models["df_model"],
        df_state=_models["df_state"],
        audio_cfg=_cfg.audio,
        df_cfg=_cfg.deep_filter,
    )
    _resampler = build_resampler(_cfg.audio)
    logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FastAPI ì•±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
app = FastAPI(title="ParkMate API Server")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup():
    global _tts_engine
    # TTS ì—”ì§„ ì´ˆê¸°í™”
    logger.info("ğŸ”Š [TTS] MeloTTS KR ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        _tts_engine = KoreanMeloTTS(speed=1.3)
        logger.info("âœ… [TTS] ëª¨ë¸ ë¡œë”© ì™„ë£Œ (device=%s)", _tts_engine.device)
    except Exception as exc:
        logger.error("âŒ [TTS] ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: %s", exc)
        _tts_engine = None

    # VAD + Whisper ëª¨ë¸ ì´ˆê¸°í™”
    _init_models()

    # LLM Warm-up
    logger.info("ğŸ”¥ [Warm-up] LLM GPU ì‚¬ì „ ì ì¬ ì‹œì‘...")
    try:
        await classify("ì‹œìŠ¤í…œ ì˜ˆì—´")
        logger.info("âœ… [Warm-up] LLM ì ì¬ ì™„ë£Œ")
    except Exception as exc:
        logger.warning("âš ï¸ [Warm-up] ì‹¤íŒ¨: %s", exc)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GET /tts/{filename} â€” TTS wav íŒŒì¼ ì„œë¹™
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/tts/{filename}")
async def serve_tts(filename: str):
    filepath = TTS_DIR / filename
    if not filepath.exists():
        return JSONResponse({"error": "file not found"}, status_code=404)
    return FileResponse(str(filepath), media_type="audio/wav")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# POST /api/plate/recognize â€” ì…/ì¶œì°¨ ì²˜ë¦¬
#   â†’ CLI ë©”ë‰´ 1(ì…ì°¨), 2(ì¶œì°¨) ì™€ ë™ì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/api/plate/recognize")
async def plate_recognize(
    plate_number: str = Form(...),
    direction: str = Form("ENTRY"),  # "ENTRY" ë˜ëŠ” "EXIT"
):
    """
    ì°¨ëŸ‰ë²ˆí˜¸ì™€ ë°©í–¥(ENTRY/EXIT)ì„ ë°›ì•„ ì…/ì¶œì°¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ì´ë¯¸ì§€ ì—…ë¡œë“œ ëŒ€ì‹  í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ (CLI ì™€ ë™ì¼).
    """
    plate = plate_number.strip()
    if not plate:
        return JSONResponse({"success": False, "message": "ì°¨ëŸ‰ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."})

    try:
        if direction.upper() == "ENTRY":
            result = entry_event.handle_entry_event(supabase, plate)
        elif direction.upper() == "EXIT":
            result = exit_event.handle_exit_event(supabase, plate)
        else:
            return JSONResponse({"success": False, "message": "directionì€ ENTRY ë˜ëŠ” EXITì´ì–´ì•¼ í•©ë‹ˆë‹¤."})

        if result.get("status") == "success":
            tts_msg = result.get("tts_message", "")
            tts_filename = _tts_to_file(tts_msg) if tts_msg else None

            return JSONResponse({
                "success": True,
                "plate": plate,
                "direction": direction.upper(),
                "message": tts_msg,
                "tts_url": f"/tts/{tts_filename}" if tts_filename else None,
                "data": result.get("data"),
                "parking_session_id": result.get("data", {}).get("session_id") if direction.upper() == "ENTRY" else None,
            })
        else:
            return JSONResponse({
                "success": False,
                "message": result.get("message", result.get("tts_message", "ì²˜ë¦¬ ì‹¤íŒ¨")),
            })

    except Exception as e:
        logger.error("[plate_recognize] ì˜¤ë¥˜: %s", e)
        return JSONResponse({"success": False, "message": str(e)})


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# POST /api/payment/demo â€” ê²°ì œ ì‹œë®¬ë ˆì´ì…˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/api/payment/demo")
async def payment_demo(body: dict):
    """
    ê²°ì œ ì‹œë®¬ë ˆì´ì…˜: v1_payment_log í…Œì´ë¸”ì— ê¸°ë¡í•©ë‹ˆë‹¤.
    body: { parking_session_id, result: "SUCCESS"|"FAIL", reason?: str }
    """
    session_id = body.get("parking_session_id")
    result = body.get("result", "SUCCESS")
    reason = body.get("reason")

    if not session_id:
        return JSONResponse({"success": False, "detail": "parking_session_id í•„ìš”"}, status_code=400)

    try:
        log_data = {
            "session_id": session_id,
            "status": result,
            "err_msg": reason if result == "FAIL" else None,
            "paid_at": datetime.now(timezone.utc).isoformat(),
        }

        supabase.table("v1_payment_log").insert(log_data).execute()

        return JSONResponse({"success": True, "result": result})

    except Exception as e:
        logger.error("[payment_demo] ì˜¤ë¥˜: %s", e)
        return JSONResponse({"success": False, "detail": str(e)}, status_code=500)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WebSocket /ws/voice â€” ë¸Œë¼ìš°ì € ë§ˆì´í¬ â†’ STT â†’ LLaMA â†’ TTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@app.websocket("/ws/voice")
async def ws_voice(ws: WebSocket):
    """
    ë¸Œë¼ìš°ì €ì—ì„œ float32 PCM (16kHz) ì˜¤ë””ì˜¤ë¥¼ ë°›ì•„
    VAD â†’ Whisper STT â†’ classify â†’ dispatch â†’ generate_reply_stream â†’ TTS
    íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

    í”„ë¡œí† ì½œ (í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„):
      - binary: float32 PCM ì˜¤ë””ì˜¤ ë²„í¼
      - text/JSON:
        { type: "tts_end" }           â†’ TTS ì¬ìƒ ì™„ë£Œ ì•Œë¦¼
        { type: "voice_mode", value } â†’ PAYMENT/NORMAL ëª¨ë“œ ì „í™˜
        { type: "vehicle_result", direction, ... } â†’ ì…/ì¶œì°¨ ê²°ê³¼ ì²˜ë¦¬
        { type: "user_activity" }     â†’ ë¬´ìŒ íƒ€ì´ë¨¸ ë¦¬ì…‹

    í”„ë¡œí† ì½œ (ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸):
      { type: "assistant_state", state: "LISTENING"|"THINKING"|"SPEAKING" }
      { type: "assistant_message", text, intent?, tts_url?, end_session? }
    """
    await ws.accept()
    logger.info("[WS] í´ë¼ì´ì–¸íŠ¸ ì—°ê²°")

    # â”€â”€ ì„¸ì…˜ ìƒíƒœ â”€â”€
    voice_mode = "NORMAL"  # NORMAL | PAYMENT
    plate_number = "ë¯¸ë“±ë¡"
    is_speaking = False
    barge_in_speech_count = 0  # barge-in ì—°ì† ìŒì„± í”„ë ˆì„ ì¹´ìš´í„°

    # â”€â”€ VAD ìƒíƒœ (ì„¸ì…˜ë³„ ë…ë¦½) â”€â”€
    speech_buffer: list[np.ndarray] = []
    pre_speech_buffer: deque = deque(maxlen=10)
    silence_frames = 0
    silence_trigger = _cfg.vad.silence_trigger_frames
    max_buffer_frames = int(_cfg.whisper.max_buffer_sec * 1000 / _cfg.audio.chunk_duration_ms)

    # VAD ëª¨ë¸ì€ ìƒíƒœë¥¼ ê°€ì§€ë¯€ë¡œ, ì„¸ì…˜ë³„ë¡œ reset
    if _models:
        _models["vad_model"].reset_states()

    # ì—°ê²° ì¦‰ì‹œ LISTENING ìƒíƒœ ì•Œë¦¼
    await ws.send_json({"type": "assistant_state", "state": "LISTENING"})

    async def send_state(state: str):
        try:
            await ws.send_json({"type": "assistant_state", "state": state})
        except Exception:
            pass

    async def send_message(text: str, intent: Optional[str] = None, tts_url: Optional[str] = None, end_session: bool = False):
        try:
            msg: dict = {"type": "assistant_message", "text": text}
            if intent:
                msg["intent"] = intent
            if tts_url:
                msg["tts_url"] = tts_url
            if end_session:
                msg["end_session"] = True
            await ws.send_json(msg)
        except Exception:
            pass

    def transcribe(audio_16k: np.ndarray) -> Optional[str]:
        """Whisper ì „ì‚¬ (ë™ê¸°, ë¸”ë¡œí‚¹)"""
        if _models is None:
            return None
        duration = len(audio_16k) / _cfg.audio.whisper_sample_rate
        if duration < _cfg.vad.min_speech_duration_sec:
            return None

        try:
            segments, info = _models["whisper_model"].transcribe(
                audio_16k,
                beam_size=_cfg.whisper.beam_size,
                language=_cfg.whisper.language,
                task=_cfg.whisper.task,
                vad_filter=_cfg.whisper.vad_filter,
            )
            text = "".join(seg.text for seg in segments).strip()
            return text if text else None
        except Exception as exc:
            logger.error("[WS STT] ì˜¤ë¥˜: %s", exc)
            return None

    async def process_stt_text(stt_text: str):
        """STT â†’ classify â†’ dispatch â†’ generate_reply_stream â†’ ë¬¸ì¥ ë‹¨ìœ„ TTS ìŠ¤íŠ¸ë¦¬ë°"""
        nonlocal is_speaking, plate_number

        await send_state("THINKING")

        # Step 1: classify (await ì§ì ‘ í˜¸ì¶œ â€” ìŠ¤ë ˆë“œ ë¸Œë¦¿ì§€ ì œê±°)
        try:
            clf = await classify(stt_text)
        except Exception as exc:
            logger.error("[Step1] ì‹¤íŒ¨: %s", exc)
            tts_file = _tts_to_file("ì£„ì†¡í•©ë‹ˆë‹¤, ì ì‹œ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            await send_message(
                "ì£„ì†¡í•©ë‹ˆë‹¤, ì ì‹œ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                tts_url=f"/tts/{tts_file}" if tts_file else None,
            )
            return

        logger.info("[Step1] intent=%s (%.0fms)", clf.intent, clf.latency_ms)

        if clf.intent == "none":
            msg = "ì˜ ëª» ë“¤ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
            tts_file = _tts_to_file(msg)
            is_speaking = True
            await send_state("SPEAKING")
            await send_message(msg, tts_url=f"/tts/{tts_file}" if tts_file else None)
            return

        # Step 2: dispatch (ë™ê¸° í•¨ìˆ˜ â€” ë¹ ë¦„)
        try:
            db_result = dispatch(supabase=supabase, plate_number=plate_number, intent=clf.intent)
        except Exception as exc:
            logger.error("[Step2] ì‹¤íŒ¨: %s", exc)
            msg = "ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            tts_file = _tts_to_file(msg)
            await send_message(msg, tts_url=f"/tts/{tts_file}" if tts_file else None)
            return

        if db_result.get("escalate"):
            msg = "ê³ ê°ë‹˜, ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹´ë‹¹ ê´€ë¦¬ìë¥¼ ì¦‰ì‹œ í˜¸ì¶œí–ˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹­ì‹œì˜¤."
            tts_file = _tts_to_file(msg)
            is_speaking = True
            await send_state("SPEAKING")
            await send_message(msg, intent=clf.intent.upper(), tts_url=f"/tts/{tts_file}" if tts_file else None)
            return

        # Step 3: ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° TTS (ì²« ë¬¸ì¥ ì™„ì„± ì¦‰ì‹œ ì „ì†¡)
        try:
            is_speaking = True
            await send_state("SPEAKING")

            sentence_buf = []       # í† í° ëˆ„ì  ë²„í¼
            full_reply_parts = []   # ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            first_sent = True

            async for chunk in generate_reply_stream(stt_text, db_result["raw_data"]):
                full_reply_parts.append(chunk)
                sentence_buf.append(chunk)
                joined = "".join(sentence_buf)

                # ë¬¸ì¥ êµ¬ë¶„ì(. ! ?) ë˜ëŠ” ì¤„ë°”ê¿ˆ ê°ì§€ ì‹œ ì¦‰ì‹œ TTS + ì „ì†¡
                if any(joined.rstrip().endswith(c) for c in (".", "!", "?")):
                    sentence = joined.strip()
                    if sentence:
                        tts_file = _tts_to_file(sentence)
                        await send_message(
                            sentence,
                            intent=clf.intent.upper() if first_sent else None,
                            tts_url=f"/tts/{tts_file}" if tts_file else None,
                        )
                        first_sent = False
                    sentence_buf.clear()

            # ì”ì—¬ í…ìŠ¤íŠ¸ ì²˜ë¦¬
            remaining = "".join(sentence_buf).strip()
            if remaining:
                tts_file = _tts_to_file(remaining)
                await send_message(
                    remaining,
                    intent=clf.intent.upper() if first_sent else None,
                    tts_url=f"/tts/{tts_file}" if tts_file else None,
                )

            full_reply = "".join(full_reply_parts).strip()
            logger.info("[Pipeline ì™„ë£Œ] '%s'", full_reply[:80])

        except Exception as exc:
            logger.error("[Step3] ì‹¤íŒ¨: %s", exc)
            msg = "ì•ˆë‚´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            tts_file = _tts_to_file(msg)
            await send_message(msg, tts_url=f"/tts/{tts_file}" if tts_file else None)

    def is_speech(chunk_16k: np.ndarray) -> bool:
        """VAD íŒë‹¨"""
        if _models is None:
            return False
        tensor = torch.from_numpy(chunk_16k).to(_models["device"]).unsqueeze(0)
        with torch.no_grad():
            prob = _models["vad_model"](tensor, _cfg.audio.whisper_sample_rate).item()
        return prob >= _cfg.vad.threshold

    # â”€â”€ WebSocket ë©”ì¸ ë£¨í”„ â”€â”€
    try:
        while True:
            data = await ws.receive()

            # â”€â”€ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ (JSON) â”€â”€
            if "text" in data:
                try:
                    msg = json.loads(data["text"])
                except json.JSONDecodeError:
                    continue

                msg_type = msg.get("type", "")

                if msg_type == "tts_end":
                    is_speaking = False
                    await send_state("LISTENING")

                elif msg_type == "voice_mode":
                    voice_mode = msg.get("value", "NORMAL")
                    logger.info("[WS] voice_mode â†’ %s", voice_mode)

                elif msg_type == "user_activity":
                    pass  # ë¬´ìŒ íƒ€ì´ë¨¸ ë¦¬ì…‹ (í˜„ì¬ ë¯¸ì‚¬ìš©)

                elif msg_type == "vehicle_result":
                    # ì…/ì¶œì°¨ ê²°ê³¼ â†’ ì•ˆë‚´ ë©˜íŠ¸ ìƒì„±
                    direction = msg.get("direction", "")
                    if direction == "ENTRY_DENIED":
                        m = "í˜„ì¬ ì£¼ì°¨ì¥ì´ ë§Œì°¨ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                        tts_file = _tts_to_file(m)
                        is_speaking = True
                        await send_state("SPEAKING")
                        await send_message(m, tts_url=f"/tts/{tts_file}" if tts_file else None)

                elif msg_type == "payment_result":
                    value = msg.get("value", "")
                    if value == "SUCCESS":
                        m = "ê²°ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì‹­ì‹œì˜¤."
                    else:
                        m = "ê²°ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜ ê´€ë¦¬ì‹¤ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
                    tts_file = _tts_to_file(m)
                    is_speaking = True
                    await send_state("SPEAKING")
                    await send_message(m, tts_url=f"/tts/{tts_file}" if tts_file else None)

                elif msg_type == "set_plate":
                    plate_number = msg.get("plate", "ë¯¸ë“±ë¡")
                    logger.info("[WS] plate â†’ %s", plate_number)

                continue

            # â”€â”€ ë°”ì´ë„ˆë¦¬ ë©”ì‹œì§€ (ì˜¤ë””ì˜¤ PCM) â”€â”€
            if "bytes" in data and data["bytes"]:
                if voice_mode == "PAYMENT":
                    logger.debug("[WS] ì˜¤ë””ì˜¤ ë¬´ì‹œ (voice_mode=%s)", voice_mode)
                    continue

                raw_bytes = data["bytes"]

                # float32 PCM íŒŒì‹± (ë¸Œë¼ìš°ì € AudioContext â†’ 16kHz)
                try:
                    n_samples = len(raw_bytes) // 4
                    audio_chunk = np.array(
                        struct.unpack(f"<{n_samples}f", raw_bytes[:n_samples * 4]),
                        dtype=np.float32,
                    )
                except Exception:
                    continue

                if len(audio_chunk) == 0:
                    continue

                # â”€â”€ VAD ì²˜ë¦¬ â”€â”€
                # Silero VADëŠ” 16kHz ê¸°ì¤€ 512 ìƒ˜í”Œ(32ms) ë‹¨ìœ„ë¡œë§Œ ì •í™•íˆ ë™ì‘.
                # ë¸Œë¼ìš°ì € ScriptProcessor(4096ìƒ˜í”Œ)ë¥¼ 512ìƒ˜í”Œì”© ë¶„í•  ì²˜ë¦¬.
                VAD_CHUNK = 512
                any_speech = False

                for i in range(0, len(audio_chunk) - VAD_CHUNK + 1, VAD_CHUNK):
                    sub = audio_chunk[i:i + VAD_CHUNK]
                    if is_speech(sub):
                        any_speech = True
                        break

                # â”€â”€ Barge-in ê°ì§€: SPEAKING ì¤‘ ìŒì„±ì´ ê°ì§€ë˜ë©´ TTS ì¤‘ë‹¨ â”€â”€
                if is_speaking:
                    if any_speech:
                        barge_in_speech_count += 1
                        if barge_in_speech_count >= 2:  # ì—°ì† 2í”„ë ˆì„ ì´ìƒ â†’ barge-in í™•ì •
                            logger.info("ğŸ”‡ [Barge-in] ì‚¬ìš©ì ìŒì„± ê°ì§€ â†’ TTS ì¤‘ë‹¨ ìš”ì²­")
                            is_speaking = False
                            barge_in_speech_count = 0
                            # TTS í ë¹„ìš°ê¸° ìœ„í•´ í´ë¼ì´ì–¸íŠ¸ì— ì•Œë¦¼
                            try:
                                await ws.send_json({"type": "barge_in"})
                            except Exception:
                                pass
                            # í˜„ì¬ í”„ë ˆì„ë¶€í„° speech_buffer ìˆ˜ì§‘ ì‹œì‘
                            speech_buffer.clear()
                            silence_frames = 0
                            if _models:
                                _models["vad_model"].reset_states()
                            speech_buffer.append(audio_chunk)
                    else:
                        barge_in_speech_count = 0
                    continue  # SPEAKING ì¤‘ì—ëŠ” ì¼ë°˜ VAD ë¡œì§ ìŠ¤í‚µ

                if any_speech:
                    if not speech_buffer and pre_speech_buffer:
                        speech_buffer.extend(pre_speech_buffer)
                        pre_speech_buffer.clear()
                    speech_buffer.append(audio_chunk)
                    silence_frames = 0
                else:
                    pre_speech_buffer.append(audio_chunk)
                    if speech_buffer:
                        silence_frames += 1

                        # ì •ì  íŠ¸ë¦¬ê±° â†’ ì „ì‚¬
                        if silence_frames >= silence_trigger:
                            audio_np = np.concatenate(speech_buffer, axis=0)
                            speech_buffer.clear()
                            silence_frames = 0
                            if _models:
                                _models["vad_model"].reset_states()

                            stt_text = transcribe(audio_np)
                            if stt_text:
                                logger.info("[WS STT] '%s'", stt_text)
                                await process_stt_text(stt_text)

                # ìµœëŒ€ ë²„í¼ íŠ¸ë¦¬ê±°
                if len(speech_buffer) >= max_buffer_frames:
                    audio_np = np.concatenate(speech_buffer, axis=0)
                    speech_buffer.clear()
                    silence_frames = 0
                    if _models:
                        _models["vad_model"].reset_states()

                    stt_text = transcribe(audio_np)
                    if stt_text:
                        logger.info("[WS STT max] '%s'", stt_text)
                        await process_stt_text(stt_text)

    except WebSocketDisconnect:
        logger.info("[WS] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
    except Exception as exc:
        logger.error("[WS] ì˜¤ë¥˜: %s", exc)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì§„ì…ì 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    uvicorn.run(
        "server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info",
    )
