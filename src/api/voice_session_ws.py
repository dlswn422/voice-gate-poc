from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState

import numpy as np
import time
import json

import src.app_state as app_state
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ğŸ§ Outdoor Parking Lot Voice Tuning
# ==================================================
SILENCE_RMS_THRESHOLD = 0.0030
END_SILENCE_SEC = 0.45
MIN_AUDIO_SEC = 0.35
SAMPLE_RATE = 16000
MIN_SPEECH_FRAMES = 1
IGNORE_INPUT_AFTER_TTS_SEC = 0.2
MAX_SPEECH_SEC = 6.0
NO_INPUT_WARN_SEC = 5.0
NO_INPUT_END_SEC = 9.0


# ==================================================
# Utils
# ==================================================
async def safe_send(ws: WebSocket, payload: dict):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.send_json(payload)


async def safe_close(ws: WebSocket):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.close()


def is_meaningful_text(text: str) -> bool:
    if not text:
        return False
    t = text.strip()
    if len(t) < 3:
        return False
    return t not in {"ì–´", "ìŒ", "ì•„", "ë„¤", "ì˜ˆ", "ì‘"}


# ==================================================
# WebSocket
# ==================================================
@router.websocket("/ws/voice")
async def voice_session_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ğŸ”Œ Voice connected")

    # -----------------------------
    # Session State
    # -----------------------------
    io_state = "LISTENING"          # LISTENING | THINKING | SPEAKING
    voice_mode = "NORMAL"           # NORMAL | PAYMENT
    exit_context = "NONE"           # NONE | UNPAID

    pcm_buffer: list[np.ndarray] = []
    collecting = False
    speech_frame_count = 0
    last_non_silence_ts = 0.0
    ignore_until_ts = 0.0

    last_activity_ts = time.time()
    no_input_warned = False

    try:
        while True:
            now = time.time()

            # ==================================================
            # â° No-input timeout (ê²°ì œ ì¤‘ ì œì™¸)
            # ==================================================
            if (
                io_state == "LISTENING"
                and not collecting
                and now >= ignore_until_ts
                and voice_mode != "PAYMENT"
            ):
                idle = now - last_activity_ts

                if idle >= NO_INPUT_END_SEC:
                    print("[TIMEOUT] âŒ No input â†’ END SESSION")

                    msg = "ì•ˆë‚´ë¥¼ ì¢…ë£Œí• ê²Œìš”."
                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": msg,
                        "tts_url": synthesize(msg),
                        "end_session": True,
                    })
                    await safe_close(websocket)
                    break

                if idle >= NO_INPUT_WARN_SEC and not no_input_warned:
                    print("[TIMEOUT] âš ï¸ No input warning")

                    no_input_warned = True
                    io_state = "SPEAKING"
                    last_activity_ts = time.time()

                    msg = "ë§ì”€ì´ ì—†ìœ¼ì‹œë©´ ì•ˆë‚´ë¥¼ ì¢…ë£Œí• ê²Œìš”."
                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": msg,
                        "tts_url": synthesize(msg),
                    })

            message = await websocket.receive()

            # ==================================================
            # ğŸ“© Frontend control messages
            # ==================================================
            if "text" in message:
                try:
                    msg = json.loads(message["text"])

                    # â—â—â— ì¶”ê°€ëœ í•µì‹¬ â—â—â—
                    if msg.get("type") == "user_activity":
                        print("[ACTIVITY] ğŸ§© User activity detected")
                        last_activity_ts = time.time()
                        continue

                    if msg.get("type") == "tts_end":
                        print("[TTS END] ğŸ”Š â†’ LISTENING")

                        io_state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        speech_frame_count = 0
                        ignore_until_ts = time.time() + IGNORE_INPUT_AFTER_TTS_SEC
                        last_activity_ts = time.time()

                        await safe_send(websocket, {
                            "type": "assistant_state",
                            "state": "LISTENING",
                        })
                        continue

                    if msg.get("type") == "voice_mode":
                        voice_mode = msg.get("value", "NORMAL")
                        print(f"[MODE] ğŸ› voice_mode = {voice_mode}")
                        continue

                    if msg.get("type") in ("vehicle_result", "payment_result"):
                        io_state = "SPEAKING"
                        last_activity_ts = time.time()
                        voice_mode = "NORMAL"

                        if msg["type"] == "vehicle_result":
                            direction = msg.get("direction")
                            reason = msg.get("reason")
                            exit_context = msg.get("exit_context", "NONE")

                            if direction == "ENTRY_DENIED" and reason == "FULL":
                                text = (
                                    "í˜„ì¬ ì£¼ì°¨ì¥ì´ ë§Œì°¨ì…ë‹ˆë‹¤.\n"
                                    "ê·¼ì²˜ ì£¼ì°¨ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                                )
                            elif direction == "ENTRY":
                                text = (
                                    "ì…ì°¨ê°€ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                                    "ë¬¸ì œê°€ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
                                )
                            elif direction == "EXIT":
                                if exit_context == "UNPAID":
                                    text = (
                                        "ë¯¸ê²°ì œ ìƒíƒœì…ë‹ˆë‹¤.\n"
                                        "ê²°ì œ í›„ ì¶œì°¨ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
                                        "í˜¹ì‹œ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
                                    )
                                else:
                                    text = (
                                        "ì¶œì°¨ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n"
                                        "ë¬¸ì œê°€ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
                                    )
                            else:
                                continue

                        else:  # payment_result
                            if msg.get("value") == "SUCCESS":
                                exit_context = "NONE"
                                text = (
                                    "ê²°ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                                    "ì°¨ëŸ‰ ë²ˆí˜¸íŒì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
                                )
                            else:
                                text = (
                                    "ê²°ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n"
                                    "í˜¹ì‹œ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
                                )

                        await safe_send(websocket, {
                            "type": "assistant_message",
                            "text": text,
                            "tts_url": synthesize(text),
                        })
                        continue

                except Exception as e:
                    print("[ERROR] âŒ Front message parse error:", e)

            # ==================================================
            # ğŸ”’ PAYMENT MODE
            # ==================================================
            if voice_mode == "PAYMENT":
                continue

            # ==================================================
            # ğŸ§ Audio frame
            # ==================================================
            if "bytes" not in message or io_state != "LISTENING":
                continue

            if now < ignore_until_ts:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            rms = float(np.sqrt(np.mean(pcm * pcm)))

            # -----------------------------
            # ğŸ¤ Speech start
            # -----------------------------
            if not collecting:
                if rms > SILENCE_RMS_THRESHOLD:
                    speech_frame_count += 1
                else:
                    speech_frame_count = 0

                if speech_frame_count >= MIN_SPEECH_FRAMES:
                    collecting = True
                    pcm_buffer.clear()
                    speech_frame_count = 0
                    last_non_silence_ts = now
                    print(f"[SPEECH START] ğŸ¤ rms={rms:.4f}")
                continue
            
            # -----------------------------
            # ğŸ™ Collecting
            # -----------------------------
            pcm_buffer.append(pcm)
            if rms > SILENCE_RMS_THRESHOLD:
                last_non_silence_ts = now

            # -----------------------------
            # ğŸ›‘ Speech end
            # -----------------------------
            if now - last_non_silence_ts >= END_SILENCE_SEC:
                collecting = False
                duration = sum(len(c) for c in pcm_buffer) / SAMPLE_RATE
                print(f"[SPEECH END] ğŸ¤ duration={duration:.2f}s")

                if duration < MIN_AUDIO_SEC:
                    pcm_buffer.clear()
                    continue

                # ğŸ”¥ THINKING ì§„ì… (UXìš© ìƒíƒœ ë¸Œë¡œë“œìºìŠ¤íŠ¸)
                io_state = "THINKING"
                await safe_send(websocket, {
                    "type": "assistant_state",
                    "state": "THINKING",
                })

                # ğŸ”¤ STT
                text = transcribe_pcm_chunks(
                    pcm_buffer,
                    whisper_model=app_state.whisper_model,
                )
                pcm_buffer.clear()

                if not is_meaningful_text(text):
                    io_state = "LISTENING"
                    await safe_send(websocket, {
                        "type": "assistant_state",
                        "state": "LISTENING",
                    })
                    continue

                last_activity_ts = time.time()

                # ğŸ¤– AppEngine ì²˜ë¦¬
                result = app_state.app_engine.handle_text(text)
                reply = result.get("text")

                if reply:
                    io_state = "SPEAKING"
                    await safe_send(websocket, {
                        **result,
                        "type": "assistant_message",
                        "tts_url": synthesize(reply),
                    })
                else:
                    io_state = "LISTENING"
                    await safe_send(websocket, {
                        "type": "assistant_state",
                        "state": "LISTENING",
                    })

    except WebSocketDisconnect:
        print("[WS] âŒ Voice disconnected")
