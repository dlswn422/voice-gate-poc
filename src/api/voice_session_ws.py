from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState

import numpy as np
import time
import json

import src.app_state as app_state
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ğŸ§ Outdoor Parking Lot Voice Tuning
# ==================================================
SILENCE_RMS_THRESHOLD = 0.0045
END_SILENCE_SEC = 0.25
MIN_AUDIO_SEC = 0.5
SAMPLE_RATE = 16000
MIN_SPEECH_FRAMES = 2
IGNORE_INPUT_AFTER_TTS_SEC = 0.2
MAX_SPEECH_SEC = 4.0
NO_INPUT_WARN_SEC = 5.0
NO_INPUT_END_SEC = 9.0


async def safe_send(ws: WebSocket, payload: dict):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.send_json(payload)


async def safe_close(ws: WebSocket):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.close()


def is_meaningful_text(text: str) -> bool:
    if not text:
        return False
    t = text.strip()
    if len(t) < 3:
        return False
    return t not in {"ì–´", "ìŒ", "ì•„", "ë„¤", "ì˜ˆ", "ì‘"}


@router.websocket("/ws/voice")
async def voice_session_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ğŸ”Œ Voice connected")

    # -----------------------------
    # Session State
    # -----------------------------
    io_state = "LISTENING"       # LISTENING | THINKING | SPEAKING
    voice_mode = "NORMAL"        # NORMAL | PAYMENT
    exit_context = "NONE"        # NONE | UNPAID

    pcm_buffer = []
    collecting = False
    speech_frame_count = 0
    speech_start_ts = 0.0
    last_non_silence_ts = 0.0
    ignore_until_ts = 0.0

    last_activity_ts = time.time()
    no_input_warned = False

    try:
        while True:
            now = time.time()

            # ==================================================
            # â° No-input timeout
            # ==================================================
            if io_state == "LISTENING" and not collecting:
                idle = now - last_activity_ts

                if idle >= NO_INPUT_END_SEC:
                    print("[TIMEOUT] âŒ No input â†’ END SESSION")
                    msg = "ì•ˆë‚´ë¥¼ ì¢…ë£Œí• ê²Œìš”."
                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": msg,
                        "tts_url": synthesize(msg),
                        "end_session": True,
                    })
                    await safe_close(websocket)
                    break

                if idle >= NO_INPUT_WARN_SEC and not no_input_warned:
                    no_input_warned = True
                    print("[TIMEOUT] âš ï¸ No input warning")
                    msg = "ë§ì”€ì´ ì—†ìœ¼ì‹œë©´ ì•ˆë‚´ë¥¼ ì¢…ë£Œí• ê²Œìš”."
                    last_activity_ts = time.time()
                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": msg,
                        "tts_url": synthesize(msg),
                    })

            message = await websocket.receive()

            # ==================================================
            # ğŸ“© Frontend Control Messages
            # ==================================================
            if "text" in message:
                try:
                    msg = json.loads(message["text"])

                    # â–¶ TTS ì¢…ë£Œ
                    if msg.get("type") == "tts_end":
                        print("[TTS END] ğŸ”Š â†’ LISTENING")
                        io_state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        speech_frame_count = 0
                        ignore_until_ts = time.time() + IGNORE_INPUT_AFTER_TTS_SEC
                        last_activity_ts = time.time()

                        await safe_send(websocket, {
                            "type": "assistant_state",
                            "state": "LISTENING",
                        })
                        continue

                    # â–¶ ìŒì„± ëª¨ë“œ
                    if msg.get("type") == "voice_mode":
                        voice_mode = msg.get("value", "NORMAL")
                        print(f"[MODE] ğŸ› voice_mode = {voice_mode}")
                        continue

                    # â–¶ ğŸš— ë²ˆí˜¸íŒ ê²°ê³¼
                    if msg.get("type") == "vehicle_result":
                        direction = msg.get("direction")
                        reason = msg.get("reason")
                        exit_context = msg.get("exit_context", "NONE")

                        if direction == "ENTRY_DENIED" and reason == "FULL":
                            text = (
                                "í˜„ì¬ ì£¼ì°¨ì¥ì´ ë§Œì°¨ì…ë‹ˆë‹¤.\n"
                                "ê·¼ì²˜ ì£¼ì°¨ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            )

                            await safe_send(websocket, {
                                "type": "assistant_message",
                                "text": text,
                                "tts_url": synthesize(text),
                                # end_session ì—†ìŒ â†’ ë¬´ìŒ íƒ€ì„ì•„ì›ƒ ì¢…ë£Œ
                            })
                            continue

                        if direction == "ENTRY":
                            text = (
                                "ì…ì°¨ê°€ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                                "ë¬¸ì œê°€ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
                            )
                            
                        elif direction == "EXIT":
                            if exit_context == "UNPAID":
                                text = (
                                "ë¯¸ê²°ì œ ìƒíƒœì…ë‹ˆë‹¤\n. ê²°ì œ í›„ ì¶œì°¨ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
                                "í˜¹ì‹œ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
                            )
                            else:
                                text = (
                                "ì¶œì°¨ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n"
                                "ë¬¸ì œê°€ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
                                )

                        await safe_send(websocket, {
                            "type": "assistant_message",
                            "text": text,
                            "tts_url": synthesize(text),
                        })

                    # â–¶ ğŸ’³ ê²°ì œ ê²°ê³¼
                    if msg.get("type") == "payment_result":
                        result = msg.get("value")

                        if result == "SUCCESS":
                            # âœ… ì„±ê³µ â†’ ì‹œìŠ¤í…œ í”Œë¡œìš°
                            exit_context = "NONE"
                            text = "ê²°ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤\n. ì¶œì°¨ë¥¼ ì§„í–‰í•˜ì„¸ìš”."

                            last_activity_ts = time.time()
                            io_state = "SPEAKING"

                            # ğŸ”¥ ì¶”ê°€: ìŒì„± ì…ë ¥ ë‹¤ì‹œ í—ˆìš©
                            voice_mode = "NORMAL"

                            await safe_send(websocket, {
                                "type": "assistant_message",
                                "text": text,
                                "tts_url": synthesize(text),
                            })
                            continue

                        else:
                            # âŒ ì‹¤íŒ¨ â†’ ìƒë‹´ í”Œë¡œìš°
                            text = (
                                "ê²°ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n"
                                "í˜¹ì‹œ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
                            )

                            last_activity_ts = time.time()
                            io_state = "SPEAKING"

                            # ğŸ”¥ ì´ë¯¸ ì˜ë¨
                            voice_mode = "NORMAL"

                            await safe_send(websocket, {
                                "type": "assistant_message",
                                "text": text,
                                "tts_url": synthesize(text),
                            })
                            continue

                except Exception as e:
                    print("[ERROR] âŒ Front message parse error:", e)

            # ==================================================
            # ğŸ”’ PAYMENT MODE â†’ mic ignore
            # ==================================================
            if voice_mode == "PAYMENT":
                continue

            # ==================================================
            # ğŸ§ Audio Frame
            # ==================================================
            if "bytes" not in message or io_state != "LISTENING":
                continue

            if now < ignore_until_ts:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            rms = float(np.sqrt(np.mean(pcm * pcm)))

            # -----------------------------
            # ğŸ¤ Speech Start
            # -----------------------------
            if not collecting:
                if rms > SILENCE_RMS_THRESHOLD:
                    speech_frame_count += 1
                else:
                    speech_frame_count = 0

                if speech_frame_count >= MIN_SPEECH_FRAMES:
                    collecting = True
                    pcm_buffer.clear()
                    speech_frame_count = 0
                    speech_start_ts = now
                    last_non_silence_ts = now
                    print("[SPEECH START] ğŸ¤")
                continue

            # -----------------------------
            # ğŸ™ Collecting
            # -----------------------------
            pcm_buffer.append(pcm)
            if rms > SILENCE_RMS_THRESHOLD:
                last_non_silence_ts = now

            # -----------------------------
            # ğŸ›‘ Speech End
            # -----------------------------
            if now - last_non_silence_ts >= END_SILENCE_SEC:
                collecting = False
                duration = sum(len(c) for c in pcm_buffer) / SAMPLE_RATE
                print(f"[SPEECH END] ğŸ¤ duration={duration:.2f}s")

                if duration < MIN_AUDIO_SEC:
                    print("[SPEECH DROP] â›” Too short")
                    pcm_buffer.clear()
                    continue

                io_state = "THINKING"
                print("[STT] ğŸ§  Transcribing...")

                text = transcribe_pcm_chunks(
                    pcm_buffer,
                    whisper_model=app_state.whisper_model,
                )
                pcm_buffer.clear()

                print(f"[STT RESULT] ğŸ“ '{text}'")

                if not is_meaningful_text(text):
                    print("[STT IGNORE] ğŸ¤· Meaningless")
                    io_state = "LISTENING"
                    continue

                last_activity_ts = time.time()

                result = app_state.app_engine.handle_text(text)
                reply = result.get("text")

                if reply:
                    io_state = "SPEAKING"
                    print("[TTS] ğŸ—£ assistant reply")
                    await safe_send(websocket, {
                        **result,
                        "type": "assistant_message",
                        "tts_url": synthesize(reply),
                    })
                else:
                    io_state = "LISTENING"

    except WebSocketDisconnect:
        print("[WS] âŒ Voice disconnected")