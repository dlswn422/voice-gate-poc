from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState

import numpy as np
import time
import json
import asyncio

import src.app_state as app_state
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ğŸ§ Outdoor Parking Lot Voice Tuning (FINAL - STABLE)
# ==================================================
# âš ï¸ ê¸°ì¤€ í™˜ê²½
# - ì‹¤ì™¸ ì£¼ì°¨ì¥
# - ì°¨ëŸ‰ ì—”ì§„ìŒ / ë°”ëŒ / ì£¼ë³€ ëŒ€í™” ì¡´ì¬
# - í‚¤ì˜¤ìŠ¤í¬ ë§ˆì´í¬ (AGC / NS / EC ì¼œì§)

# â–¶ ë¬´ìŒ íŒë‹¨ RMS ê¸°ì¤€
# - 0.003~0.004 : ì‹¤ë‚´
# - 0.004~0.005 : ì‹¤ì™¸(ê¶Œì¥)
# - 0.006â†‘      : ì‘ì€ ëª©ì†Œë¦¬ ì¸ì‹ ì‹¤íŒ¨ ê°€ëŠ¥
SILENCE_RMS_THRESHOLD = 0.0045

# â–¶ ë°œí™” ì¢…ë£Œë¡œ íŒë‹¨í•˜ëŠ” ì¹¨ë¬µ ì‹œê°„ (ì´ˆ)
# - ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬¸ì¥ ì¤‘ê°„ ëŠê¹€
# - ë„ˆë¬´ ê¸¸ë©´ ì‘ë‹µ ëŠë¦¼
END_SILENCE_SEC = 0.25

# â–¶ ë°œí™” ì¤‘ ì ê¹ ë©ˆì·„ì„ ë•Œ STT pre-run ì‹œì‘ ì‹œì 
# - ì²´ê° ì‘ë‹µ ì†ë„ ê°œì„ ìš©
PRERUN_SILENCE_SEC = 0.3

# â–¶ ìµœì†Œ ìŒì„± ê¸¸ì´ (ì´ˆ)
# - ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ì˜ë¯¸ ì—†ëŠ” ì†Œë¦¬ë¡œ íŒë‹¨
MIN_AUDIO_SEC = 0.5

# â–¶ STT pre-run ì‹œ ë’¤ìª½ ì¡ìŒ ì»· (ì´ˆ)
CUT_AUDIO_SEC = 0.2

SAMPLE_RATE = 16000

# â–¶ ë°œí™” ì‹œì‘ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ì—°ì† í”„ë ˆì„ ìˆ˜
# - ê°’ì´ í´ìˆ˜ë¡ ì†ŒìŒì— ê°•í•¨, ëŒ€ì‹  ë°˜ì‘ ëŠë¦¼
MIN_SPEECH_FRAMES = 2

# â–¶ TTS ì¢…ë£Œ ì§í›„ ì…ë ¥ ë¬´ì‹œ ì‹œê°„
# - TTS ìê¸° ìŒì„± ì¬ì¸ì‹ ë°©ì§€
# - ë„ˆë¬´ ê¸¸ë©´ ì‚¬ìš©ìê°€ ë°”ë¡œ ë§í•´ë„ ì•ˆ ì¡í˜
IGNORE_INPUT_AFTER_TTS_SEC = 0.2

# â–¶ ìµœëŒ€ ë°œí™” í—ˆìš© ì‹œê°„ (ì´ˆ)
# - ë„ˆë¬´ ê¸¸ë©´ ê°•ì œ ì¢…ë£Œ
MAX_SPEECH_SEC = 4.0

# â–¶ ë°œí™” ì¢…ë£Œ ì§í›„ ì§§ì€ ë¬´ì‹œ êµ¬ê°„
POST_SPEECH_IGNORE_SEC = 0.25

# â–¶ ì•„ë¬´ ë§ë„ ì—†ì„ ë•Œ ìë™ ì¢…ë£Œ ì‹œê°„
NO_INPUT_TIMEOUT_SEC = 8.0


# ==================================================
# ğŸ”’ WS utils
# ==================================================
async def safe_send(ws: WebSocket, payload: dict):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.send_json(payload)


async def safe_close(ws: WebSocket):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.close()


# ==================================================
# ğŸ§  ì˜ë¯¸ ì—†ëŠ” ë°œí™” í•„í„°
# ==================================================
def is_meaningful_text(text: str) -> bool:
    """
    STT ê²°ê³¼ê°€ ì‹¤ì œ ì˜ë¯¸ ìˆëŠ” ë°œí™”ì¸ì§€ íŒë‹¨
    - ë„ˆë¬´ ì§§ì€ ë°œí™” ì œê±°
    - ì¶”ì„ìƒˆ / ê°íƒ„ì‚¬ ì œê±°
    """
    if not text:
        return False

    t = text.strip()

    # ê¸€ì ìˆ˜ ê¸°ì¤€
    if len(t) < 3:
        return False

    meaningless = {
        "ì–´", "ìŒ", "ì•„", "ë„¤", "ì˜ˆ",
        "ì–´ì–´", "ìŒìŒ", "ì‘", "ì–´?", "ìŒ?"
    }

    if t in meaningless:
        return False

    return True


# ==================================================
# ğŸ¤ Voice WebSocket
# ==================================================
@router.websocket("/ws/voice")
async def voice_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ğŸ”Œ Client connected")

    # â–¶ ì„œë²„ ê¸°ì¤€ IO ìƒíƒœ
    # LISTENING : ë§ˆì´í¬ ì…ë ¥ í—ˆìš©
    # THINKING  : STT / LLM ì²˜ë¦¬ ì¤‘
    # SPEAKING  : TTS ì¬ìƒ ì¤‘
    io_state = "LISTENING"

    pcm_buffer: list[np.ndarray] = []
    collecting = False

    speech_start_ts = 0.0
    last_non_silence_ts = 0.0
    ignore_until_ts = 0.0

    speech_frame_count = 0
    prerun_task: asyncio.Task | None = None

    # â–¶ ë§ˆì§€ë§‰ ì‚¬ìš©ì í™œë™ ì‹œê°„
    last_activity_ts = time.time()

    try:
        while True:
            # --------------------------------------------------
            # ğŸ•’ ë¬´ì‘ë‹µ ìë™ ì¢…ë£Œ
            # --------------------------------------------------
            if io_state == "LISTENING":
                if time.time() - last_activity_ts > NO_INPUT_TIMEOUT_SEC:
                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": "ì‘ë‹µì´ ì—†ì–´ ì•ˆë‚´ë¥¼ ì¢…ë£Œí• ê²Œìš”.",
                        "end_session": True,
                    })
                    await safe_close(websocket)
                    break

            message = await websocket.receive()

            # --------------------------------------------------
            # ğŸ” í”„ë¡ íŠ¸ â†’ TTS ì¢…ë£Œ ì•Œë¦¼
            # --------------------------------------------------
            if "text" in message:
                try:
                    msg = json.loads(message["text"])
                    if msg.get("type") == "tts_end":
                        io_state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        prerun_task = None
                        speech_frame_count = 0
                        ignore_until_ts = time.time() + IGNORE_INPUT_AFTER_TTS_SEC
                        last_activity_ts = time.time()
                        continue
                except Exception:
                    pass

            # --------------------------------------------------
            # ğŸ§ ì˜¤ë””ì˜¤ í”„ë ˆì„
            # --------------------------------------------------
            if "bytes" not in message:
                continue

            if io_state != "LISTENING":
                continue

            now = time.time()
            if now < ignore_until_ts:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            rms = float(np.sqrt(np.mean(pcm * pcm)))

            # --------------------------------------------------
            # ğŸ¤ ë°œí™” ì‹œì‘ ê°ì§€
            # --------------------------------------------------
            if not collecting:
                if rms > SILENCE_RMS_THRESHOLD:
                    speech_frame_count += 1
                else:
                    speech_frame_count = 0

                if speech_frame_count >= MIN_SPEECH_FRAMES:
                    collecting = True
                    pcm_buffer.clear()
                    prerun_task = None
                    speech_frame_count = 0
                    speech_start_ts = now
                    last_non_silence_ts = now
                continue

            # --------------------------------------------------
            # ğŸ™ ë°œí™” ìˆ˜ì§‘
            # --------------------------------------------------
            pcm_buffer.append(pcm)

            if rms > SILENCE_RMS_THRESHOLD:
                last_non_silence_ts = now

            silence_time = now - last_non_silence_ts
            speech_duration = now - speech_start_ts

            # --------------------------------------------------
            # âš¡ STT pre-run
            # --------------------------------------------------
            if prerun_task is None and silence_time >= PRERUN_SILENCE_SEC:
                audio = np.concatenate(pcm_buffer).astype(np.float32)
                cut = int(SAMPLE_RATE * CUT_AUDIO_SEC)
                if audio.size > cut:
                    audio = audio[:-cut]

                prerun_task = asyncio.create_task(
                    asyncio.to_thread(
                        transcribe_pcm_chunks,
                        [audio],
                        app_state.whisper_model,
                    )
                )

            # --------------------------------------------------
            # ğŸ›‘ ë°œí™” ì¢…ë£Œ íŒë‹¨
            # --------------------------------------------------
            if silence_time >= END_SILENCE_SEC or speech_duration >= MAX_SPEECH_SEC:
                collecting = False
                io_state = "THINKING"
                ignore_until_ts = time.time() + POST_SPEECH_IGNORE_SEC

                total_samples = sum(len(c) for c in pcm_buffer)
                if total_samples / SAMPLE_RATE < MIN_AUDIO_SEC:
                    pcm_buffer.clear()
                    prerun_task = None
                    io_state = "LISTENING"
                    last_activity_ts = time.time()
                    continue

                await safe_send(websocket, {
                    "type": "assistant_state",
                    "state": "THINKING",
                })

                if prerun_task:
                    try:
                        text = await prerun_task
                    except Exception:
                        text = ""
                else:
                    text = transcribe_pcm_chunks(
                        pcm_buffer,
                        whisper_model=app_state.whisper_model,
                    )

                pcm_buffer.clear()
                prerun_task = None

                if not is_meaningful_text(text):
                    io_state = "LISTENING"
                    last_activity_ts = time.time()
                    continue

                last_activity_ts = time.time()
                print(f"[STT] {text}")

                # --------------------------------------------------
                # ğŸ§  AppEngine
                # --------------------------------------------------
                result = app_state.app_engine.handle_text(text)

                reply_text = result.get("text", "")
                end_session = result.get("end_session", False)

                if reply_text:
                    io_state = "SPEAKING"
                    tts_url = synthesize(reply_text)

                    payload = dict(result)
                    payload["tts_url"] = tts_url

                    await safe_send(websocket, payload)

                if end_session:
                    await safe_close(websocket)
                    break

    except WebSocketDisconnect:
        print("[WS] âŒ Client disconnected")

    except Exception as e:
        print("[WS] ğŸ’¥ Error:", repr(e))
        await safe_close(websocket)
