from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import numpy as np
import time
import json

import src.app_state as app_state
from src.speech.vad import VoiceActivityDetector
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ğŸ”§ íŠœë‹ í¬ì¸íŠ¸ (ì•ˆì „í•œ ê¸°ë³¸ê°’)
# ==================================================

# RMS ê¸°ì¤€: ë°°ê²½ ì†ŒìŒ vs ì‹¤ì œ ë°œí™” êµ¬ë¶„ìš©
SILENCE_RMS_THRESHOLD = 0.008

# ğŸ”¥ ê°€ì¥ ì¤‘ìš”í•œ ì²´ê° ì†ë„ í¬ì¸íŠ¸
# ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨í•˜ëŠ” ëŒ€ê¸° ì‹œê°„
# (ê¸°ì¡´ 0.7 â†’ 0.4 : ì •í™•ë„ ìœ ì§€ + ë°˜ì‘ ë¹¨ë¼ì§)
END_SILENCE_SEC = 0.4

# ë„ˆë¬´ ì§§ì€ ë°œí™”ëŠ” STT ì•ˆ íƒœìš°ê¸° (ì†ë„ + ì˜¤ì‘ë™ ë°©ì§€)
MIN_AUDIO_SEC = 0.5


@router.websocket("/ws/voice")
async def voice_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ğŸ”Œ Client connected")

    # --------------------------------------------------
    # Silero VAD
    # - ì—­í• : "ë§ ì‹œì‘ ê°ì§€" ì „ìš©
    # - ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ë§¤ chunkë§ˆë‹¤ ì“°ì§€ ì•ŠìŒ (ì¤‘ìš”)
    # --------------------------------------------------
    vad = VoiceActivityDetector()

    pcm_buffer: list[np.ndarray] = []
    collecting = False
    last_non_silence_ts = 0.0

    # ìµœì´ˆ ìƒíƒœ
    app_state.app_engine.state = "LISTENING"

    try:
        while True:
            # ==================================================
            # 0ï¸âƒ£ ë©”ì‹œì§€ ìˆ˜ì‹  (audio frame or control)
            # ==================================================
            message = await websocket.receive()

            # ---------- (A) í”„ë¡ íŠ¸ ì œì–´ ë©”ì‹œì§€ ----------
            if "text" in message:
                try:
                    msg = json.loads(message["text"])
                    if msg.get("type") == "tts_end":
                        # TTS ë â†’ ë‹¤ì‹œ ë“£ê¸° ìƒíƒœ
                        app_state.app_engine.state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        print("[WS] ğŸ” TTS ended â†’ LISTENING")
                        continue
                except Exception:
                    continue

            # ---------- (B) ì˜¤ë””ì˜¤ í”„ë ˆì„ ----------
            if "bytes" not in message:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            now = time.time()

            # ==================================================
            # 1ï¸âƒ£ RMS ê³„ì‚° (ì¹¨ë¬µ/ì†Œë¦¬ íŒë‹¨)
            # ==================================================
            rms = np.sqrt(np.mean(pcm * pcm))

            # ==================================================
            # 2ï¸âƒ£ ì„œë²„ ì°¨ë‹¨ êµ¬ê°„
            # THINKING / SPEAKING ì¤‘ì—ëŠ”
            # ì‚¬ìš©ì ìŒì„± ë¬´ì‹œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            # ==================================================
            if app_state.app_engine.state in ("SPEAKING", "THINKING"):
                collecting = False
                pcm_buffer.clear()
                continue

            # ==================================================
            # 3ï¸âƒ£ ë°œí™” ì‹œì‘ íŒë‹¨
            # --------------------------------------------------
            # âœ”ï¸ ì•„ì§ collecting ì „:
            #     â†’ Silero VAD + RMS
            # âœ”ï¸ collecting ì´í›„:
            #     â†’ RMSë§Œ ì‚¬ìš© (ì†ë„/ì•ˆì •ì„±)
            # ==================================================
            if not collecting:
                is_speech = vad.is_speech(pcm) or rms > SILENCE_RMS_THRESHOLD
            else:
                is_speech = rms > SILENCE_RMS_THRESHOLD

            if is_speech:
                if not collecting:
                    collecting = True
                    pcm_buffer.clear()
                    print("[WS] ğŸ¤ Speech started")

                pcm_buffer.append(pcm)
                last_non_silence_ts = now
                continue

            # ==================================================
            # 4ï¸âƒ£ ë°œí™” ì¢…ë£Œ íŒë‹¨
            # ==================================================
            if collecting and (now - last_non_silence_ts) >= END_SILENCE_SEC:
                print("[WS] ğŸ›‘ Speech ended")
                collecting = False

                if not pcm_buffer:
                    continue

                # ì „ì²´ ìŒì„± ê¸¸ì´ ê³„ì‚° (ì´ˆ)
                total_samples = sum(len(chunk) for chunk in pcm_buffer)
                total_audio_sec = total_samples / 16000.0

                # ë„ˆë¬´ ì§§ì€ ë°œí™”ëŠ” ë¬´ì‹œ
                if total_audio_sec < MIN_AUDIO_SEC:
                    pcm_buffer.clear()
                    app_state.app_engine.state = "LISTENING"
                    print("[WS] â­ï¸ Too short audio â†’ skip STT")
                    continue

                # ==================================================
                # 5ï¸âƒ£ í”„ë¡ íŠ¸ì— THINKING ì•Œë¦¼ (ì²´ê° ì†ë„)
                # ==================================================
                await websocket.send_json({
                    "type": "assistant_state",
                    "state": "THINKING",
                })
                print("[WS] ğŸ’­ THINKING sent to client")

                # ==================================================
                # 6ï¸âƒ£ STT
                # ==================================================
                text = transcribe_pcm_chunks(
                    pcm_buffer,
                    whisper_model=app_state.whisper_model,
                )
                pcm_buffer.clear()

                if not text:
                    app_state.app_engine.state = "LISTENING"
                    continue

                print(f"[STT] {text}")

                # ==================================================
                # 7ï¸âƒ£ AppEngine ì²˜ë¦¬
                # ==================================================
                app_state.app_engine.state = "THINKING"
                result = app_state.app_engine.handle_text(text)

                reply_text = result.get("text", "")
                conversation_state = result.get(
                    "conversation_state", "WAITING_USER"
                )
                end_session = result.get("end_session", False)

                print(f"[BOT] {reply_text} ({conversation_state})")

                # ==================================================
                # 8ï¸âƒ£ TTS
                # ==================================================
                tts_url = None
                if reply_text:
                    app_state.app_engine.state = "SPEAKING"
                    tts_url = synthesize(reply_text)

                # ==================================================
                # 9ï¸âƒ£ í”„ë¡ íŠ¸ë¡œ ì‘ë‹µ
                # ==================================================
                await websocket.send_json({
                    "type": "assistant_message",
                    "text": reply_text,
                    "tts_url": tts_url,
                    "conversation_state": conversation_state,
                    "end_session": end_session,
                })

                # ==================================================
                # ğŸ”Ÿ ëŒ€í™” ì¢…ë£Œ
                # ==================================================
                if end_session:
                    app_state.app_engine.state = "LISTENING"
                    collecting = False
                    pcm_buffer.clear()
                    print("[WS] ğŸ›‘ Conversation ended")

    except WebSocketDisconnect:
        print("[WS] âŒ Client disconnected")

    except Exception as e:
        print("[WS] ğŸ’¥ Error:", repr(e))
        await websocket.close()
