from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import numpy as np
import time
import json

import src.app_state as app_state
from src.speech.vad import VoiceActivityDetector
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ðŸ”§ íŠœë‹ í¬ì¸íŠ¸ (ì•ˆì „í•œ ê¸°ë³¸ê°’)
# ==================================================

# RMS ê¸°ì¤€: ë°°ê²½ ì†ŒìŒ vs ì‹¤ì œ ë°œí™” êµ¬ë¶„ìš©
SILENCE_RMS_THRESHOLD = 0.008

# ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨í•˜ëŠ” ì¹¨ë¬µ ì‹œê°„
END_SILENCE_SEC = 0.4

# ë„ˆë¬´ ì§§ì€ ë°œí™”ëŠ” STT ì•ˆ íƒœìš°ê¸°
MIN_AUDIO_SEC = 0.5


@router.websocket("/ws/voice")
async def voice_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ðŸ”Œ Client connected")

    # --------------------------------------------------
    # VAD (ë°œí™” ì‹œìž‘ ê°ì§€ìš©)
    # --------------------------------------------------
    vad = VoiceActivityDetector()

    pcm_buffer: list[np.ndarray] = []
    collecting = False
    last_non_silence_ts = 0.0

    # ìµœì´ˆ ìƒíƒœëŠ” ëŒ€ê¸°
    app_state.app_engine.state = "LISTENING"

    try:
        while True:
            # ==================================================
            # 0ï¸âƒ£ ë©”ì‹œì§€ ìˆ˜ì‹ 
            # ==================================================
            message = await websocket.receive()

            # ---------- í”„ë¡ íŠ¸ ì œì–´ ----------
            if "text" in message:
                try:
                    msg = json.loads(message["text"])
                    if msg.get("type") == "tts_end":
                        app_state.app_engine.state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        print("[WS] ðŸ” TTS ended â†’ LISTENING")
                        continue
                except Exception:
                    continue

            # ---------- ì˜¤ë””ì˜¤ í”„ë ˆìž„ ----------
            if "bytes" not in message:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            now = time.time()

            # ==================================================
            # 1ï¸âƒ£ RMS ê³„ì‚°
            # ==================================================
            rms = np.sqrt(np.mean(pcm * pcm))

            # ==================================================
            # 2ï¸âƒ£ ì„œë²„ ì°¨ë‹¨ êµ¬ê°„
            # ==================================================
            if app_state.app_engine.state in ("SPEAKING", "THINKING"):
                collecting = False
                pcm_buffer.clear()
                continue

            # ==================================================
            # 3ï¸âƒ£ ë°œí™” ì‹œìž‘ íŒë‹¨
            # ==================================================
            if not collecting:
                is_speech = vad.is_speech(pcm) or rms > SILENCE_RMS_THRESHOLD
            else:
                is_speech = rms > SILENCE_RMS_THRESHOLD

            if is_speech:
                if not collecting:
                    collecting = True
                    pcm_buffer.clear()
                    print("[WS] ðŸŽ¤ Speech started")

                pcm_buffer.append(pcm)
                last_non_silence_ts = now
                continue

            # ==================================================
            # 4ï¸âƒ£ ë°œí™” ì¢…ë£Œ íŒë‹¨
            # ==================================================
            if collecting and (now - last_non_silence_ts) >= END_SILENCE_SEC:
                print("[WS] ðŸ›‘ Speech ended")
                collecting = False

                if not pcm_buffer:
                    continue

                total_samples = sum(len(chunk) for chunk in pcm_buffer)
                total_audio_sec = total_samples / 16000.0

                if total_audio_sec < MIN_AUDIO_SEC:
                    pcm_buffer.clear()
                    app_state.app_engine.state = "LISTENING"
                    print("[WS] â­ï¸ Too short audio â†’ skip STT")
                    continue

                # ==================================================
                # 5ï¸âƒ£ THINKING ì•Œë¦¼ (UX)
                # ==================================================
                await websocket.send_json({
                    "type": "assistant_state",
                    "state": "THINKING",
                })
                print("[WS] ðŸ’­ THINKING sent to client")

                # ==================================================
                # 6ï¸âƒ£ STT
                # ==================================================
                text = transcribe_pcm_chunks(
                    pcm_buffer,
                    whisper_model=app_state.whisper_model,
                )
                pcm_buffer.clear()

                if not text:
                    app_state.app_engine.state = "LISTENING"
                    continue

                print(f"[STT] {text}")

                # ==================================================
                # 7ï¸âƒ£ AppEngine
                # ==================================================
                app_state.app_engine.state = "THINKING"
                result = app_state.app_engine.handle_text(text)

                reply_text = result.get("text", "")
                conversation_state = result.get(
                    "conversation_state", "WAITING_USER"
                )
                end_session = result.get("end_session", False)

                print(f"[BOT] {reply_text} ({conversation_state})")

                # ==================================================
                # 8ï¸âƒ£ TTS
                # ==================================================
                tts_url = None
                if reply_text:
                    app_state.app_engine.state = "SPEAKING"
                    tts_url = synthesize(reply_text)

                # ==================================================
                # 9ï¸âƒ£ í”„ë¡ íŠ¸ ì‘ë‹µ
                # ==================================================
                await websocket.send_json({
                    "type": "assistant_message",
                    "text": reply_text,
                    "tts_url": tts_url,
                    "conversation_state": conversation_state,
                    "end_session": end_session,
                })

                # ==================================================
                # ðŸ”Ÿ ëŒ€í™” ì™„ì „ ì¢…ë£Œ
                # ==================================================
                if end_session:
                    app_state.app_engine.state = "IDLE"
                    collecting = False
                    pcm_buffer.clear()
                    print("[WS] ðŸ›‘ Conversation ended â†’ IDLE")

    except WebSocketDisconnect:
        print("[WS] âŒ Client disconnected")

    except Exception as e:
        print("[WS] ðŸ’¥ Error:", repr(e))
        await websocket.close()
