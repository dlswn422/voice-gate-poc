from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState

import numpy as np
import time
import json
import asyncio

import src.app_state as app_state
from src.speech.whisper_service import transcribe_pcm_chunks
from src.speech.tts import synthesize

router = APIRouter()

# ==================================================
# ğŸ§ Audio tuning (ì†ŒìŒ ë¬´ì‹œ ìµœì¢…ê°’)
# ==================================================
SILENCE_RMS_THRESHOLD = 0.003   # ì‹œì‘ ê°ì§€ìš© (ì¢…ë£Œì—ëŠ” ê±°ì˜ ì˜í–¥ ì—†ìŒ)
END_SILENCE_SEC = 0.1          # ì¡°ìš©í•  ë•Œ ë¹ ë¥¸ ì¢…ë£Œìš©
PRERUN_SILENCE_SEC = 0.2
MIN_AUDIO_SEC = 0.5
CUT_AUDIO_SEC = 0.2
SAMPLE_RATE = 16000

MIN_SPEECH_FRAMES = 3
IGNORE_INPUT_AFTER_TTS_SEC = 0.35

MAX_SPEECH_SEC = 3.5            # â­â­â­ í•µì‹¬: ì†ŒìŒ ìˆì–´ë„ ë¬´ì¡°ê±´ ì¢…ë£Œ â­â­â­


# ==================================================
# ğŸ”’ WebSocket utils
# ==================================================
async def safe_send(ws: WebSocket, payload: dict):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.send_json(payload)


async def safe_close(ws: WebSocket):
    if ws.application_state == WebSocketState.CONNECTED:
        await ws.close()


@router.websocket("/ws/voice")
async def voice_ws(websocket: WebSocket):
    await websocket.accept()
    print("[WS] ğŸ”Œ Client connected")

    # IO ìƒíƒœ (ì—”ì§„ ìƒíƒœë‘ ì™„ì „íˆ ë¶„ë¦¬)
    io_state = "LISTENING"   # LISTENING | SPEAKING

    pcm_buffer: list[np.ndarray] = []
    collecting = False
    last_non_silence_ts = 0.0
    speech_start_ts = 0.0

    prerun_task: asyncio.Task | None = None
    speech_frame_count = 0
    ignore_until_ts = 0.0

    try:
        while True:
            message = await websocket.receive()

            # --------------------------------------------------
            # í”„ë¡ íŠ¸ ì œì–´ ë©”ì‹œì§€ (TTS ì¢…ë£Œ)
            # --------------------------------------------------
            if "text" in message:
                try:
                    msg = json.loads(message["text"])
                    if msg.get("type") == "tts_end":
                        print("[WS] ğŸ” TTS ended â†’ LISTENING")
                        io_state = "LISTENING"
                        collecting = False
                        pcm_buffer.clear()
                        prerun_task = None
                        speech_frame_count = 0
                        ignore_until_ts = time.time() + IGNORE_INPUT_AFTER_TTS_SEC
                        continue
                except Exception:
                    pass

            # --------------------------------------------------
            # ì˜¤ë””ì˜¤ í”„ë ˆì„
            # --------------------------------------------------
            if "bytes" not in message:
                continue

            # ğŸ”´ ë§í•˜ëŠ” ì¤‘ì—” ë§ˆì´í¬ ì™„ì „ ë¬´ì‹œ
            if io_state == "SPEAKING":
                continue

            if time.time() < ignore_until_ts:
                continue

            pcm = np.frombuffer(message["bytes"], dtype=np.float32)
            if pcm.size == 0:
                continue

            now = time.time()
            rms = np.sqrt(np.mean(pcm * pcm))

            # --------------------------------------------------
            # ğŸ¤ ë°œí™” ì‹œì‘ ê°ì§€
            # --------------------------------------------------
            if not collecting:
                if rms > SILENCE_RMS_THRESHOLD:
                    speech_frame_count += 1
                else:
                    speech_frame_count = 0

                if speech_frame_count >= MIN_SPEECH_FRAMES:
                    collecting = True
                    pcm_buffer.clear()
                    prerun_task = None
                    speech_frame_count = 0
                    last_non_silence_ts = now
                    speech_start_ts = now
                    print("[WS] ğŸ¤ Speech started")
                continue

            # --------------------------------------------------
            # ë°œí™” ìˆ˜ì§‘
            # --------------------------------------------------
            pcm_buffer.append(pcm)

            if rms > SILENCE_RMS_THRESHOLD:
                last_non_silence_ts = now

            silence_time = now - last_non_silence_ts
            speech_duration = now - speech_start_ts

            # --------------------------------------------------
            # STT pre-run
            # --------------------------------------------------
            if prerun_task is None and silence_time >= PRERUN_SILENCE_SEC:
                print("[WS] âš¡ STT pre-run")
                audio = np.concatenate(pcm_buffer).astype(np.float32)
                cut_samples = int(SAMPLE_RATE * CUT_AUDIO_SEC)
                if audio.size > cut_samples:
                    audio = audio[:-cut_samples]

                prerun_task = asyncio.create_task(
                    asyncio.to_thread(
                        transcribe_pcm_chunks,
                        [audio],
                        app_state.whisper_model,
                    )
                )

            # --------------------------------------------------
            # ğŸ›‘ ë°œí™” ì¢…ë£Œ (ì¹¨ë¬µ OR ì‹œê°„ ê°•ì œ ì¢…ë£Œ)
            # --------------------------------------------------
            if (
                silence_time >= END_SILENCE_SEC
                or speech_duration >= MAX_SPEECH_SEC
            ):
                collecting = False
                print("[WS] ğŸ›‘ Speech ended")

                total_samples = sum(len(c) for c in pcm_buffer)
                total_audio_sec = total_samples / SAMPLE_RATE

                if total_audio_sec < MIN_AUDIO_SEC:
                    pcm_buffer.clear()
                    prerun_task = None
                    continue

                if prerun_task:
                    try:
                        text = await prerun_task
                        print("[WS] âš¡ pre-run STT reused")
                    except Exception:
                        text = ""
                else:
                    text = transcribe_pcm_chunks(
                        pcm_buffer,
                        whisper_model=app_state.whisper_model,
                    )

                pcm_buffer.clear()
                prerun_task = None

                if not text:
                    continue

                print(f"[STT] {text}")

                # ==================================================
                # ğŸ§  AppEngine ë‹¨ì¼ ì§„ì…ì  (ì›ë˜ êµ¬ì¡° ìœ ì§€)
                # ==================================================
                result = app_state.app_engine.handle_text(text)

                reply_text = result.get("text", "")
                conversation_state = result.get("conversation_state", "WAITING_USER")
                end_session = result.get("end_session", False)

                if reply_text:
                    io_state = "SPEAKING"
                    tts_url = synthesize(reply_text)

                    await safe_send(websocket, {
                        "type": "assistant_message",
                        "text": reply_text,
                        "tts_url": tts_url,
                        "conversation_state": conversation_state,
                        "end_session": end_session,
                    })

                if end_session:
                    print("[WS] ğŸ›‘ Conversation ended")
                    await safe_close(websocket)
                    break

    except WebSocketDisconnect:
        print("[WS] âŒ Client disconnected")

    except Exception as e:
        print("[WS] ğŸ’¥ Error:", repr(e))
        await safe_close(websocket)
