# src/nlu/llm_client.py
from __future__ import annotations

import json
import os
import re
import time
import traceback
import requests

from src.nlu.intent_schema import IntentResult, Intent

# ==================================================
# Ollama Native Chat API ì„¤ì •
# ==================================================
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434").rstrip("/")
OLLAMA_MODEL = os.getenv(
    "OLLAMA_INTENT_MODEL",
    os.getenv("OLLAMA_MODEL", "llama3.1:8b"),
)
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "20"))

OLLAMA_CHAT_URL = f"{OLLAMA_BASE_URL}/api/chat"

_JSON_RE = re.compile(r"\{[\s\S]*?\}")

# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LEVEL-1 INTENT ONLY)
# ==================================================
SYSTEM_PROMPT_INTENT = (
    "ë„ˆëŠ” ì£¼ì°¨ì¥ í‚¤ì˜¤ìŠ¤í¬ ìŒì„± ì‹œìŠ¤í…œì˜ 1ì°¨ ì˜ë„ ë¶„ë¥˜ê¸°ë‹¤.\n\n"
    "ì—­í• :\n"
    "- ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ 'ì£¼ì œ ë‹¨ìœ„(Level-1 Intent)'ë¡œë§Œ ë¶„ë¥˜í•œë‹¤\n"
    "- í•´ê²° ë°©ë²• ì œì‹œ, ì‹¤í–‰ íŒë‹¨, ëŒ€í™” ìƒì„±ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
    "- HOW_TO, ISSUE, ERROR ê°™ì€ ì„¸ë¶€ ì›ì¸ì€ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤\n\n"
    "[ì˜ë„ ëª©ë¡]\n"
    "- ENTRY        (ì…ì°¨ ê´€ë ¨)\n"
    "- EXIT         (ì¶œì°¨ ê´€ë ¨)\n"
    "- PAYMENT      (ìš”ê¸ˆ/ê²°ì œ/ì •ì‚° ê´€ë ¨)\n"
    "- REGISTRATION (ë°©ë¬¸ì/ì°¨ëŸ‰ ë“±ë¡ ê´€ë ¨)\n"
    "- TIME_PRICE   (ì‹œê°„/ìš”ê¸ˆ ì •ì±… ë¬¸ì˜)\n"
    "- FACILITY     (ì°¨ë‹¨ê¸°/ê¸°ê¸° ì´ìƒ)\n"
    "- COMPLAINT    (ë¶ˆë§Œ/ì§œì¦/í˜¼ë€ í‘œí˜„)\n"
    "- NONE         (ì£¼ì°¨ì¥ê³¼ ë¬´ê´€)\n\n"
    "[ë¶„ë¥˜ ê·œì¹™]\n"
    "- ëª…ë ¹ì²˜ëŸ¼ ë³´ì—¬ë„ 'ì˜ë„'ê°€ ì•„ë‹ˆë¼ 'ì£¼ì œ'ë¡œ ë¶„ë¥˜í•œë‹¤\n"
    "- ë¬¸ì œ ìƒí™©ê³¼ ë°©ë²• ë¬¸ì˜ë¥¼ êµ¬ë¶„í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
    "- ì• ë§¤í•´ë„ ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ì˜ë„ë¥¼ ì„ íƒí•œë‹¤\n\n"
    "[ì¶œë ¥ ê·œì¹™]\n"
    "- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤\n"
    "- í˜•ì‹: {\"intent\": \"INTENT_NAME\"}\n"
    "- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
)

# ==================================================
# JSON ì¶”ì¶œ ìœ í‹¸
# ==================================================
def _extract_json(text: str) -> dict:
    if not text:
        raise ValueError("Empty LLM output")

    # 1ï¸âƒ£ ì½”ë“œë¸”ë¡ ì œê±°
    text = text.strip()
    text = re.sub(r"```.*?```", "", text, flags=re.S)

    # 2ï¸âƒ£ ì²« JSON ê°ì²´ë§Œ ì¶”ì¶œ
    m = re.search(r"\{[^{}]*\}", text)
    if m:
        return json.loads(m.group(0))

    # 3ï¸âƒ£ ë§ˆì§€ë§‰ fallback: intent í‚¤ë§Œ ê°•ì œ ì¶”ì¶œ
    m = re.search(r'"intent"\s*:\s*"([A-Z_]+)"', text)
    if m:
        return {"intent": m.group(1)}

    raise ValueError(f"JSON not found in output: {text}")

# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ (INTENT ONLY)
# ==================================================
def detect_intent_llm(text: str, debug: bool = True) -> IntentResult:
    """
    1ì°¨ ì˜ë„ ë¶„ë¥˜ ì „ìš© í•¨ìˆ˜

    - ì…ë ¥: STTë¡œ í™•ì •ëœ ì‚¬ìš©ì ë°œí™”
    - ì¶œë ¥: IntentResult (intent + confidence)
    - ì´ ë‹¨ê³„ì—ì„œëŠ” ì ˆëŒ€ í•´ê²°í•˜ì§€ ì•ŠëŠ”ë‹¤
    """

    if not text or not text.strip():
        return IntentResult(intent=Intent.NONE, confidence=0.0)

    if debug:
        print(f"[LLM] (Intent-1) Input text: {text}")
        print(f"[LLM] (Intent-1) model={OLLAMA_MODEL}")

    prompt = (
        SYSTEM_PROMPT_INTENT
        + "\n\n[ì‚¬ìš©ì ë°œí™”]\n"
        + text
    )

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "stream": False,
        "options": {
            # ë¶„ë¥˜ëŠ” í”ë“¤ë¦¬ë©´ ì•ˆ ë˜ë¯€ë¡œ ê³ ì •
            "temperature": 0.0,
            # JSON í•˜ë‚˜ë§Œ ë‚˜ì˜¤ë©´ ì¶©ë¶„
            "num_predict": 16,
        },
    }

    try:
        print("[LLM] â³ Intent-1 inference started...")
        start_ts = time.time()

        r = requests.post(
            OLLAMA_CHAT_URL,
            json=payload,
            timeout=OLLAMA_TIMEOUT,
        )
        r.raise_for_status()

        elapsed_ms = (time.time() - start_ts) * 1000
        print(f"[LLM] âœ… Intent-1 inference finished ({elapsed_ms:.0f} ms)")

        data = r.json()
        content = data.get("message", {}).get("content", "")

        if debug:
            print("[LLM] (Intent-1) Raw output:")
            print(content)

        obj = _extract_json(content)
        intent_str = str(obj.get("intent", "NONE")).strip()

        try:
            intent = Intent(intent_str)
        except Exception:
            intent = Intent.NONE

        print(f"[LLM] ğŸ¯ Intent-1 classified: {intent.name}")

        # confidenceëŠ” ì—¬ê¸°ì„œ ê³„ì‚°í•˜ì§€ ì•ŠëŠ”ë‹¤
        return IntentResult(
            intent=intent,
            confidence=0.0,
        )

    except Exception as e:
        print("[LLM] âŒ Intent-1 inference failed")
        if debug:
            print(repr(e))
            traceback.print_exc()

        return IntentResult(
            intent=Intent.NONE,
            confidence=0.0,
        )