from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import json

from nlu.intent_schema import IntentResult, Intent


# ==================================================
# ëª¨ë¸ ì„¤ì •
# ==================================================

MODEL_NAME = "Qwen/Qwen2.5-1.5B-Instruct"
CACHE_DIR = "models"

_MODEL = None
_TOKENIZER = None


# ==================================================
# Qwen ëª¨ë¸ ë¡œë”© (í”„ë¡œì„¸ìŠ¤ ë‚´ 1íšŒ)
# ==================================================

def load_qwen():
    """
    Qwen LLM ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ 1íšŒë§Œ ë¡œë”©í•œë‹¤.

    - ì„œë²„ ì‹¤í–‰ ì‹œ ìµœì´ˆ 1íšŒë§Œ í˜¸ì¶œ
    - ì´í›„ detect_intent_llm í˜¸ì¶œì—ì„œëŠ” ì¬ì‚¬ìš©
    """
    global _MODEL, _TOKENIZER

    if _MODEL is None:
        print("â³ Qwen LLM ë¡œë”© ì¤‘...")

        _TOKENIZER = AutoTokenizer.from_pretrained(
            MODEL_NAME,
            trust_remote_code=True,
            cache_dir=CACHE_DIR,
        )

        _MODEL = AutoModelForCausalLM.from_pretrained(
            MODEL_NAME,
            device_map="cpu",              # 1ì°¨ ë¶„ë¥˜ìš©ì´ë¯€ë¡œ CPU ì‚¬ìš©
            torch_dtype=torch.float32,
            cache_dir=CACHE_DIR,
        )

        _MODEL.eval()
        print("âœ… Qwen LLM ë¡œë”© ì™„ë£Œ")

    return _MODEL, _TOKENIZER


# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ (ì£¼ì°¨ì¥ CX ì „ìš©)
# ==================================================

def detect_intent_llm(text: str, debug: bool = True) -> IntentResult:
    """
    ì£¼ì°¨ì¥ í‚¤ì˜¤ìŠ¤í¬ í™˜ê²½ì—ì„œ ì‚¬ìš©ìì˜ ë°œí™”ë¥¼
    'ìƒí™© / ë¬¸ì œ / ë¬¸ì˜' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” 1ì°¨ ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜

    âš ï¸ ì£¼ì˜
    - ì´ í•¨ìˆ˜ëŠ” 'ì‹¤í–‰ íŒë‹¨'ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤
    - ì œì–´ ëª…ë ¹(ë¬¸ ì—´ì–´ ë“±)ì„ ì§ì ‘ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤
    - ì• ë§¤í•œ ë°œí™”ëŠ” confidenceë¥¼ ë‚®ê²Œ ë°˜í™˜í•œë‹¤
    """
    model, tokenizer = load_qwen()

    if debug:
        print(f"ğŸ“¥ [LLM INPUT] {text}")

    # ==================================================
    # LLM í”„ë¡¬í”„íŠ¸ (1ì°¨ ë¶„ë¥˜ ì „ìš©)
    # ==================================================
    messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” 'ì£¼ì°¨ì¥ í‚¤ì˜¤ìŠ¤í¬ CX' ì „ìš© ìŒì„± ì˜ë„ ë¶„ë¥˜ AIë‹¤.\n\n"
                "ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ì•„ë˜ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ë¼.\n"
                "ì´ ë¶„ë¥˜ëŠ” 'ì œì–´ ëª…ë ¹'ì´ ì•„ë‹ˆë¼ 'ìƒí™© / ë¬¸ì œ / ë¬¸ì˜'ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤.\n\n"

                "[ì˜ë„ ëª©ë¡]\n"
                "- ENTRY_FLOW_ISSUE: ì…ì°¨í•˜ë ¤ëŠ” ìƒí™©ì—ì„œ ì°¨ë‹¨ê¸°ê°€ ì—´ë¦¬ì§€ ì•ŠìŒ\n"
                "- EXIT_FLOW_ISSUE: ì¶œì°¨í•˜ë ¤ëŠ” ìƒí™©ì—ì„œ ì°¨ë‹¨ê¸°ê°€ ì—´ë¦¬ì§€ ì•ŠìŒ\n"
                "- PAYMENT_ISSUE: ì£¼ì°¨ ìš”ê¸ˆ ê²°ì œì™€ ê´€ë ¨ëœ ë¬¸ì œ ë°œìƒ\n"
                "- REGISTRATION_ISSUE: ì°¨ëŸ‰ / ë°©ë¬¸ì / ë²ˆí˜¸íŒ ë“±ë¡ ë¬¸ì œ\n"
                "- TIME_ISSUE: ì£¼ì°¨ ì‹œê°„, ë¬´ë£Œ ì‹œê°„, ì´ˆê³¼ ì‹œê°„ê³¼ ê´€ë ¨ëœ ë¬¸ì˜ ë˜ëŠ” ë¬¸ì œ ì¸ì‹\n"
                "- PRICE_INQUIRY: ì£¼ì°¨ ìš”ê¸ˆ ë˜ëŠ” ì •ì‚° ê¸ˆì•¡ì— ëŒ€í•œ ë‹¨ìˆœ ë¬¸ì˜\n"
                "- HOW_TO_EXIT: ì¶œì°¨ ë°©ë²•ì— ëŒ€í•œ ë¬¸ì˜\n"
                "- HOW_TO_REGISTER: ë°©ë¬¸ì ë˜ëŠ” ì°¨ëŸ‰ ë“±ë¡ ë°©ë²•ì— ëŒ€í•œ ë¬¸ì˜\n"
                "- COMPLAINT: ë¶ˆë§Œ, ì§œì¦, í˜¼ë€ ë“± ê°ì • ë˜ëŠ” ìƒíƒœ í‘œí˜„ (ì›ì¸ ë¶ˆëª…)\n"
                "- NONE: ì£¼ì°¨ì¥ ì´ìš©ê³¼ ë¬´ê´€í•œ ë°œí™”\n\n"

                "[ì¤‘ìš” ê·œì¹™]\n"
                "- 'ë¬¸ ì—´ì–´', 'ë‚˜ê°€ì•¼ ë¼ìš”' ê°™ì€ í‘œí˜„ì€ ëª…ë ¹ì´ ì•„ë‹ˆë¼ ìƒí™© ì„¤ëª…ìœ¼ë¡œ ë³¸ë‹¤\n"
                "- ë¬¸ì œì¸ì§€, ë°©ë²• ë¬¸ì˜ì¸ì§€, ë‹¨ìˆœ ë¶ˆë§Œì¸ì§€ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤\n"
                "- ì• ë§¤í•œ ê²½ìš° ê°€ì¥ ê°€ê¹Œìš´ ì˜ë„ë¥¼ ì„ íƒí•˜ë˜ confidenceë¥¼ ë‚®ê²Œ ì„¤ì •í•œë‹¤\n"
                "- ì ˆëŒ€ ì‹¤í–‰ íŒë‹¨ì„ í•˜ì§€ ë§ê³  ë¶„ë¥˜ë§Œ ìˆ˜í–‰í•œë‹¤\n\n"

                "[ì¶œë ¥ ê·œì¹™]\n"
                "- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤\n"
                "- í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤:\n"
                "  {\"intent\": \"INTENT_NAME\", \"confidence\": 0.0}\n"
            ),
        },
        {
            "role": "user",
            "content": text,
        },
    ]

    # ==================================================
    # ì…ë ¥ í† í° ìƒì„±
    # ==================================================
    input_ids = tokenizer.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors="pt",
    )

    # ==================================================
    # LLM ì¶”ë¡  (ê²°ì •ì  ì¶œë ¥)
    # ==================================================
    with torch.no_grad():
        output_ids = model.generate(
            input_ids=input_ids,
            max_new_tokens=64,
            do_sample=False,                # 1ì°¨ ë¶„ë¥˜ì´ë¯€ë¡œ deterministic
            eos_token_id=tokenizer.eos_token_id,
        )

    generated_ids = output_ids[0][input_ids.shape[-1]:]
    decoded = tokenizer.decode(generated_ids, skip_special_tokens=True)

    if debug:
        print("ğŸ§¾ [LLM RAW OUTPUT]")
        print(decoded)

    # ==================================================
    # JSON íŒŒì‹± + Enum ë³€í™˜
    # ==================================================
    try:
        # LLM ì¶œë ¥ì—ì„œ JSON ì˜ì—­ë§Œ ì¶”ì¶œ
        start = decoded.find("{")
        end = decoded.rfind("}") + 1
        data = json.loads(decoded[start:end])

        intent_str = data.get("intent", "NONE")
        confidence = float(data.get("confidence", 0.0))

        # Intent Enum ë³€í™˜ (ì‹¤íŒ¨ ì‹œ NONE ì²˜ë¦¬)
        try:
            intent = Intent(intent_str)
        except ValueError:
            intent = Intent.NONE

        # confidence ê°’ ì•ˆì „ ë³´ì •
        confidence = max(0.0, min(confidence, 1.0))

        if debug:
            print(
                f"ğŸ“Š [LLM PARSED] intent={intent.name}, "
                f"confidence={confidence:.2f}"
            )

        return IntentResult(intent=intent, confidence=confidence)

    except Exception as e:
        if debug:
            print("âŒ [LLM PARSE ERROR]", e)

        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ NONE ë°˜í™˜
        return IntentResult(intent=Intent.NONE, confidence=0.0)