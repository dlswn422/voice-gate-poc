from __future__ import annotations

import json
import os
import re
import time
import traceback
import requests

from src.nlu.intent_schema import IntentResult, Intent


# ==================================================
# Ollama Native Chat API ì„¤ì • (Intent-1 ì „ìš©)
# ==================================================
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434").rstrip("/")
OLLAMA_MODEL = os.getenv(
    "OLLAMA_INTENT_MODEL",
    os.getenv("OLLAMA_MODEL", "llama3.1:8b"),
)

# â± timeout ë‹¨ì¶• (tail latency ë°©ì§€)
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "30"))

OLLAMA_CHAT_URL = f"{OLLAMA_BASE_URL}/api/chat"


# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê²½ëŸ‰í™” ë²„ì „)
# ==================================================
SYSTEM_PROMPT_INTENT = (
    "ë„ˆëŠ” ì£¼ì°¨ì¥ í‚¤ì˜¤ìŠ¤í¬ ìŒì„± ì‹œìŠ¤í…œì˜ 1ì°¨ ì˜ë„ ë¶„ë¥˜ê¸°ë‹¤.\n"
    "ì‚¬ìš©ì ë°œí™”ë¥¼ Level-1 ì£¼ì œë¡œë§Œ ë¶„ë¥˜í•œë‹¤.\n\n"
    "ì˜ë„ ëª©ë¡:\n"
    "ENTRY, EXIT, PAYMENT, REGISTRATION, TIME_PRICE, FACILITY, COMPLAINT, NONE\n\n"
    "ê·œì¹™:\n"
    "- í•´ê²° ë°©ë²• ì œì‹œ ê¸ˆì§€\n"
    "- ì„¸ë¶€ ì›ì¸ êµ¬ë¶„ ê¸ˆì§€\n"
    "- ì£¼ì œ ê¸°ì¤€ìœ¼ë¡œë§Œ ë¶„ë¥˜\n\n"
    "ì¶œë ¥(JSON only):\n"
    "{\"intent\": \"INTENT_NAME\"}"
)


# ==================================================
# JSON ì¶”ì¶œ ìœ í‹¸ (ì„±ëŠ¥ ìµœì í™”)
# ==================================================
def _extract_json(text: str) -> dict:
    """
    LLM ì¶œë ¥ì—ì„œ intent JSONì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•œë‹¤.
    ë¹ ë¥¸ ê²½ë¡œ â†’ ì‹¤íŒ¨ ì‹œ ë°©ì–´ ë¡œì§
    """
    if not text:
        raise ValueError("Empty LLM output")

    t = text.strip()

    # ğŸš€ Fast-path: ìˆœìˆ˜ JSONì¸ ê²½ìš° (ëŒ€ë¶€ë¶„)
    if t.startswith("{") and t.endswith("}"):
        return json.loads(t)

    # 1) ê°€ì¥ í° JSON ë¸”ë¡
    start = t.find("{")
    end = t.rfind("}") + 1
    if start != -1 and end > start:
        try:
            return json.loads(t[start:end])
        except Exception:
            pass

    # 2) ì§§ì€ JSON ë¸”ë¡
    m = re.search(r"\{.*?\}", t, flags=re.S)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            pass

    # 3) fallback: intent í‚¤ë§Œ ì¶”ì¶œ
    m = re.search(r'"intent"\s*:\s*"([A-Z_]+)"', t)
    if m:
        return {"intent": m.group(1)}

    raise ValueError(f"JSON not found in output: {t}")


# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ (INTENT ONLY)
# ==================================================
def detect_intent_llm(text: str, debug: bool = True) -> IntentResult:
    """
    1ì°¨(Level-1) ì˜ë„ ë¶„ë¥˜ ì „ìš© í•¨ìˆ˜

    - ì…ë ¥: STT í™•ì • ë°œí™”
    - ì¶œë ¥: IntentResult(intent, confidence=0.0)

    âš ï¸ ì£¼ì˜
    - ì´ í•¨ìˆ˜ëŠ” ì ˆëŒ€ í•´ê²°í•˜ì§€ ì•ŠëŠ”ë‹¤
    - confidence ê³„ì‚°ì€ AppEngine ì±…ì„
    """
    if not text or not text.strip():
        return IntentResult(intent=Intent.NONE, confidence=0.0)

    if debug:
        print(f"[LLM] (Intent-1) Input text: {text}")
        print(f"[LLM] (Intent-1) model={OLLAMA_MODEL}")

    prompt = SYSTEM_PROMPT_INTENT + "\n\n[ì‚¬ìš©ì ë°œí™”]\n" + text

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "stream": False,
        "options": {
            # ğŸ”’ ë¶„ë¥˜ ì•ˆì •ì„± ìœ ì§€
            "temperature": 0.0,

            # ğŸš€ í† í° ìƒì„± ìµœì†Œí™”
            "num_predict": 12,

            # ğŸš€ íƒìƒ‰ ê³µê°„ ì¶•ì†Œ
            "top_k": 20,

            # ğŸš€ context window ì¶•ì†Œ
            "num_ctx": 512,
        },
    }

    try:
        if debug:
            print("[LLM] â³ Intent-1 inference started...")
        start_ts = time.time()

        r = requests.post(
            OLLAMA_CHAT_URL,
            json=payload,
            timeout=OLLAMA_TIMEOUT,
        )
        r.raise_for_status()

        elapsed_ms = (time.time() - start_ts) * 1000
        if debug:
            print(f"[LLM] âœ… Intent-1 inference finished ({elapsed_ms:.0f} ms)")

        data = r.json()
        content = (data.get("message") or {}).get("content", "") or ""

        if debug:
            print("[LLM] (Intent-1) Raw output:")
            print(content)

        obj = _extract_json(content)
        intent_str = str(obj.get("intent", "NONE")).strip()

        try:
            intent = Intent(intent_str)
        except Exception:
            intent = Intent.NONE

        if debug:
            print(f"[LLM] ğŸ¯ Intent-1 classified: {intent.name}")

        return IntentResult(intent=intent, confidence=0.0)

    except Exception as e:
        print("[LLM] âŒ Intent-1 inference failed")
        if debug:
            print(repr(e))
            traceback.print_exc()

        # ì‹¤íŒ¨ ì‹œì—ë„ ì‹œìŠ¤í…œì€ ë©ˆì¶”ì§€ ì•ŠëŠ”ë‹¤
        return IntentResult(intent=Intent.NONE, confidence=0.0)
