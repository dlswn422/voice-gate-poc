from __future__ import annotations

import json
import os
import re
import time
import traceback
import requests

from src.nlu.intent_schema import IntentResult, Intent


# ==================================================
# Ollama Native Chat API ì„¤ì • (Intent-1 ì „ìš©)
# ==================================================
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434").rstrip("/")
OLLAMA_MODEL = os.getenv(
    "OLLAMA_INTENT_MODEL",
    os.getenv("OLLAMA_MODEL", "llama3.1:8b"),
)
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "20"))

OLLAMA_CHAT_URL = f"{OLLAMA_BASE_URL}/api/chat"


# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LEVEL-1 ONLY)
# ==================================================
SYSTEM_PROMPT_INTENT = (
    "ë„ˆëŠ” ì£¼ì°¨ì¥ í‚¤ì˜¤ìŠ¤í¬ ìŒì„± ì‹œìŠ¤í…œì˜ 1ì°¨ ì˜ë„ ë¶„ë¥˜ê¸°ë‹¤.\n\n"
    "ì—­í• :\n"
    "- ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ 'ì£¼ì œ ë‹¨ìœ„(Level-1 Intent)'ë¡œë§Œ ë¶„ë¥˜í•œë‹¤\n"
    "- í•´ê²° ë°©ë²• ì œì‹œ, ì‹¤í–‰ íŒë‹¨, ëŒ€í™” ìƒì„±ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
    "- HOW_TO, ISSUE, ERROR ê°™ì€ ì„¸ë¶€ ì›ì¸ì€ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤\n\n"
    "[ì˜ë„ ëª©ë¡]\n"
    "- ENTRY        (ì…ì°¨ ê´€ë ¨)\n"
    "- EXIT         (ì¶œì°¨ ê´€ë ¨)\n"
    "- PAYMENT      (ìš”ê¸ˆ/ê²°ì œ/ì •ì‚° ê´€ë ¨)\n"
    "- REGISTRATION (ë°©ë¬¸ì/ì°¨ëŸ‰ ë“±ë¡ ê´€ë ¨)\n"
    "- TIME_PRICE   (ì‹œê°„/ìš”ê¸ˆ ì •ì±… ë¬¸ì˜)\n"
    "- FACILITY     (ì°¨ë‹¨ê¸°/ê¸°ê¸° ì´ìƒ)\n"
    "- COMPLAINT    (ë¶ˆë§Œ/ì§œì¦/í˜¼ë€ í‘œí˜„)\n"
    "- NONE         (ì£¼ì°¨ì¥ê³¼ ë¬´ê´€)\n\n"
    "[ë¶„ë¥˜ ê·œì¹™]\n"
    "- ëª…ë ¹ì²˜ëŸ¼ ë³´ì—¬ë„ 'í–‰ë™'ì´ ì•„ë‹Œ 'ì£¼ì œ'ë¡œ ë¶„ë¥˜í•œë‹¤\n"
    "- ë¬¸ì œ ìƒí™©ê³¼ ë°©ë²• ë¬¸ì˜ë¥¼ êµ¬ë¶„í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
    "- ì• ë§¤í•´ë„ ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ì˜ë„ë¥¼ ì„ íƒí•œë‹¤\n\n"
    "[ì¶œë ¥ ê·œì¹™]\n"
    "- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤\n"
    "- í˜•ì‹: {\"intent\": \"INTENT_NAME\"}\n"
    "- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤\n"
)

# ==================================================
# ì¬ì‹œë„ ì „ìš© í”„ë¡¬í”„íŠ¸ (Intent.NONE ë°©ì§€ìš©)
# ==================================================
SYSTEM_PROMPT_INTENT_RETRY = (
    SYSTEM_PROMPT_INTENT
    + "\n\n"
    "âš ï¸ ì£¼ì˜:\n"
    "ì•„ë˜ ë°œí™”ëŠ” ìŒì„± ì¸ì‹ ê²°ê³¼ë¼ ë¬¸ì¥ì´ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ì–´ìƒ‰í•  ìˆ˜ ìˆë‹¤.\n"
    "ê·¸ë˜ë„ ê°€ì¥ ê°€ê¹Œìš´ ì˜ë„ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ ì„ íƒí•˜ë¼.\n"
)


# ==================================================
# JSON ì¶”ì¶œ ìœ í‹¸ (ë°©ì–´ì )
# ==================================================
def _extract_json(text: str) -> dict:
    """
    LLM ì¶œë ¥ì—ì„œ intent JSONì„ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•œë‹¤.
    """
    if not text:
        raise ValueError("Empty LLM output")

    text = text.strip()

    # 1ï¸âƒ£ ì½”ë“œë¸”ë¡ ì œê±°
    text = re.sub(r"```.*?```", "", text, flags=re.S)

    # 2ï¸âƒ£ JSON ê°ì²´ ì¶”ì¶œ
    m = re.search(r"\{[^{}]*\}", text)
    if m:
        return json.loads(m.group(0))

    # 3ï¸âƒ£ fallback: intent í‚¤ë§Œ ê°•ì œ ì¶”ì¶œ
    m = re.search(r'"intent"\s*:\s*"([A-Z_]+)"', text)
    if m:
        return {"intent": m.group(1)}

    raise ValueError(f"JSON not found in output: {text}")


# ==================================================
# ë‚´ë¶€ í˜¸ì¶œ í•¨ìˆ˜ (ë‹¨ì¼ ì‹œë„)
# ==================================================
def _classify_once(prompt: str, debug: bool) -> Intent:
    payload = {
        "model": OLLAMA_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "stream": False,
        "options": {
            "temperature": 0.0,
            "num_predict": 16,
        },
    }

    r = requests.post(
        OLLAMA_CHAT_URL,
        json=payload,
        timeout=OLLAMA_TIMEOUT,
    )
    r.raise_for_status()

    data = r.json()
    content = data.get("message", {}).get("content", "")

    if debug:
        print("[LLM] (Intent-1) Raw output:")
        print(content)

    obj = _extract_json(content)
    intent_str = str(obj.get("intent", "NONE")).strip()

    try:
        return Intent(intent_str)
    except Exception:
        return Intent.NONE


# ==================================================
# 1ì°¨ ì˜ë„ ë¶„ë¥˜ (INTENT ONLY, retry 1íšŒ)
# ==================================================
def detect_intent_llm(text: str, debug: bool = True) -> IntentResult:
    """
    1ì°¨(Level-1) ì˜ë„ ë¶„ë¥˜ ì „ìš© í•¨ìˆ˜

    ì •ì±…:
    - 1íšŒ ì‹œë„
    - Intent.NONEì´ë©´ í”„ë¡¬í”„íŠ¸ ë³€ê²½ í›„ 1íšŒ ì¬ì‹œë„
    - ê·¸ë˜ë„ ì‹¤íŒ¨í•˜ë©´ NONE í™•ì •
    """

    if not text or not text.strip():
        return IntentResult(intent=Intent.NONE, confidence=0.0)

    if debug:
        print(f"[LLM] (Intent-1) Input text: {text}")
        print(f"[LLM] (Intent-1) model={OLLAMA_MODEL}")

    try:
        print("[LLM] â³ Intent-1 inference started...")
        start_ts = time.time()

        # ------------------------------
        # 1ì°¨ ì‹œë„
        # ------------------------------
        prompt = SYSTEM_PROMPT_INTENT + "\n\n[ì‚¬ìš©ì ë°œí™”]\n" + text
        intent = _classify_once(prompt, debug)

        # ------------------------------
        # Intent.NONE â†’ ì¬ì‹œë„ 1íšŒ
        # ------------------------------
        if intent == Intent.NONE:
            if debug:
                print("[LLM] ğŸ” Intent.NONE â†’ retry once with relaxed prompt")

            retry_prompt = (
                SYSTEM_PROMPT_INTENT_RETRY
                + "\n\n[ì‚¬ìš©ì ë°œí™”]\n"
                + text
            )
            intent = _classify_once(retry_prompt, debug)

        elapsed_ms = (time.time() - start_ts) * 1000
        print(f"[LLM] âœ… Intent-1 inference finished ({elapsed_ms:.0f} ms)")
        print(f"[LLM] ğŸ¯ Intent-1 classified: {intent.name}")

        return IntentResult(
            intent=intent,
            confidence=0.0,  # AppEngineì—ì„œ ê³„ì‚°
        )

    except Exception as e:
        print("[LLM] âŒ Intent-1 inference failed")
        if debug:
            print(repr(e))
            traceback.print_exc()

        return IntentResult(
            intent=Intent.NONE,
            confidence=0.0,
        )
