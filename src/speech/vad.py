import numpy as np
import torch
from silero_vad import load_silero_vad, get_speech_timestamps


class VoiceActivityDetector:
    """
    Silero VAD ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± í™œë™ ê°ì§€ê¸°

    ì—­í• :
    - PCM(Float32) ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìž…ë ¥
    - í˜„ìž¬ chunkê°€ ìŒì„±ì¸ì§€ ì—¬ë¶€ íŒë‹¨
    - ì¼ì • ì‹œê°„ ë¬´ìŒ ì§€ì† ì‹œ 'ë°œí™” ì¢…ë£Œ' íŒë‹¨

    ì „ì œ:
    - sample_rate = 16000
    - mono channel
    """

    def __init__(
        self,
        sample_rate: int = 16000,
        speech_threshold: float = 0.5,
        min_speech_duration_ms: int = 200,
        min_silence_duration_ms: int = 600,
    ):
        self.sample_rate = sample_rate
        self.speech_threshold = speech_threshold

        self.min_speech_duration_ms = min_speech_duration_ms
        self.min_silence_duration_ms = min_silence_duration_ms

        # ðŸ”¥ ë°œí™” ì¢…ë£Œ íŒë‹¨ìš© (ì´ˆ ë‹¨ìœ„)
        self.end_silence_sec = min_silence_duration_ms / 1000.0

        # Silero VAD ëª¨ë¸ ë¡œë“œ (CPU)
        self.model, self.utils = load_silero_vad()
        (
            self.get_speech_timestamps,
            self.save_audio,
            self.read_audio,
            self.VADIterator,
            self.collect_chunks,
        ) = self.utils

        # ë‚´ë¶€ ë²„í¼ (ì§§ì€ êµ¬ê°„ íŒë‹¨ìš©)
        self._recent_audio = np.array([], dtype=np.float32)
        self._recent_max_sec = 1.0  # ìµœê·¼ 1ì´ˆë§Œ ìœ ì§€

    def is_speech(self, pcm: np.ndarray) -> bool:
        """
        ìž…ë ¥ PCM chunkê°€ ìŒì„±ì¸ì§€ ì—¬ë¶€ ë°˜í™˜

        Args:
            pcm: np.ndarray (float32, mono)

        Returns:
            bool: ìŒì„±ìœ¼ë¡œ íŒë‹¨ë˜ë©´ True
        """

        if pcm.dtype != np.float32:
            pcm = pcm.astype(np.float32)

        # ìµœê·¼ ì˜¤ë””ì˜¤ ë²„í¼ì— ì¶”ê°€
        self._recent_audio = np.concatenate([self._recent_audio, pcm])

        # ìµœê·¼ Nì´ˆë§Œ ìœ ì§€
        max_len = int(self.sample_rate * self._recent_max_sec)
        if self._recent_audio.size > max_len:
            self._recent_audio = self._recent_audio[-max_len:]

        if self._recent_audio.size < int(self.sample_rate * 0.2):
            # ë„ˆë¬´ ì§§ìœ¼ë©´ íŒë‹¨í•˜ì§€ ì•ŠìŒ
            return False

        # Torch tensor ë³€í™˜
        audio_tensor = torch.from_numpy(self._recent_audio)

        # Silero VAD ì‹¤í–‰
        speech_timestamps = get_speech_timestamps(
            audio_tensor,
            self.model,
            sampling_rate=self.sample_rate,
            threshold=self.speech_threshold,
            min_speech_duration_ms=self.min_speech_duration_ms,
            min_silence_duration_ms=self.min_silence_duration_ms,
        )

        return len(speech_timestamps) > 0