import torch
import numpy as np
from silero_vad import load_silero_vad, get_speech_timestamps


class VoiceActivityDetector:
    """
    Silero VAD ê¸°ë°˜ ìŒì„± í™œë™ ê°ì§€ê¸° (ìŠ¤íŠ¸ë¦¬ë° ìµœì í™” ë²„ì „)

    âœ” ì—­í• :
        - "ì§€ê¸ˆ ì‚¬ëžŒì´ ë§ì„ ì‹œìž‘í–ˆëŠ”ì§€?" ë§Œ íŒë‹¨
    âŒ í•˜ì§€ ì•ŠëŠ” ê²ƒ:
        - ë§ì´ ëë‚¬ëŠ”ì§€ íŒë‹¨ âŒ
        - ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ë§¤ chunkë§ˆë‹¤ ì •ë°€ ë¶„ì„ âŒ

    ðŸ‘‰ ë§ ì¢…ë£Œ íŒë‹¨ì€ voice_ws.pyì—ì„œ
       RMS + ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” êµ¬ì¡°
    """

    def __init__(self, device: str = "cpu"):
        self.device = device

        # --------------------------------------------------
        # Silero VAD ëª¨ë¸ (JIT, ê°€ë³ê³  ì •í™•)
        # --------------------------------------------------
        self.model = load_silero_vad()
        self.model.to(self.device)

        # ì˜¤ë””ì˜¤ ì„¤ì • (ê³ ì •)
        self.sample_rate = 16000

        # --------------------------------------------------
        # ðŸ”§ íŠœë‹ í¬ì¸íŠ¸ (ì•ˆì „í•œ ê¸°ë³¸ê°’)
        # --------------------------------------------------
        # ì´ ê°’ë“¤ì€ "ë§ì´ ì‹œìž‘ëë‹¤"ë¥¼ ë¹„êµì  ë¹ ë¥´ê²Œ
        # ê°ì§€í•˜ê¸° ìœ„í•œ ì„¤ì •
        self.min_speech_ms = 200     # ê¸°ì¡´ 250 â†’ ì•½ê°„ ë¹ ë¥´ê²Œ
        self.min_silence_ms = 300    # ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ íŒë‹¨ì—ëŠ” ì‚¬ìš© ì•ˆ í•¨

    def is_speech(self, pcm: np.ndarray) -> bool:
        """
        ë‹¨ì¼ PCM chunkì— 'ë§ ì‹œìž‘ ì§•í›„'ê°€ ìžˆëŠ”ì§€ íŒë‹¨

        âœ” True  â†’ ì‚¬ëžŒì´ ë§ì„ ì‹œìž‘í–ˆë‹¤ê³  ë´„
        âœ” False â†’ ì•„ì§ ì¹¨ë¬µ ë˜ëŠ” ìž¡ìŒ

        âš ï¸ ì£¼ì˜:
        - ì´ í•¨ìˆ˜ëŠ” collecting ì‹œìž‘ ì „(=ì¹¨ë¬µ ìƒíƒœ)ì—ì„œë§Œ
          í˜¸ì¶œë˜ëŠ” ê²ƒì´ ì •ìƒ
        """

        if pcm is None or len(pcm) == 0:
            return False

        # numpy â†’ torch
        # copy()ëŠ” non-writable warning ë°©ì§€ìš©
        audio = torch.from_numpy(pcm.copy()).float().to(self.device)

        # --------------------------------------------------
        # Silero VAD í˜¸ì¶œ
        # --------------------------------------------------
        # get_speech_timestampsëŠ” ì›ëž˜
        # "ê¸´ ì˜¤ë””ì˜¤ ì „ì²´ ë¶„ì„" ìš©ë„ì´ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” "ë§ ì‹œìž‘ íŠ¸ë¦¬ê±°"ë¡œë§Œ ì‚¬ìš©
        timestamps = get_speech_timestamps(
            audio,
            self.model,
            sampling_rate=self.sample_rate,
            min_speech_duration_ms=self.min_speech_ms,
            min_silence_duration_ms=self.min_silence_ms,
        )

        # í•˜ë‚˜ë¼ë„ ìž¡ížˆë©´ "ë§ ì‹œìž‘"
        return len(timestamps) > 0
