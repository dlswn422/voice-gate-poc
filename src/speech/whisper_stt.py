import time
import sounddevice as sd
import numpy as np
import whisper
import scipy.signal
from typing import Optional, Callable

# =========================
# Whisper ëª¨ë¸ ì‹±ê¸€í†¤
# =========================
_WHISPER_MODEL = None


def get_whisper_model(model_size: str):
    global _WHISPER_MODEL
    if _WHISPER_MODEL is None:
        print("â³ Whisper ëª¨ë¸ ìµœì´ˆ 1íšŒ ë¡œë”© ì¤‘...")
        _WHISPER_MODEL = whisper.load_model(model_size)
        print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return _WHISPER_MODEL


# =========================
# í…ìŠ¤íŠ¸ ì •ê·œí™”
# =========================
def normalize_text(text: str) -> str:
    noises = ["ã…‹ã…‹", "ã…ã…", "ìŒ", "ì–´", "ì•„", "ê·¸", ",", ".", "!", "?"]
    for n in noises:
        text = text.replace(n, "")
    return text.strip()


# =========================
# Intent íŒë³„ (ìµœì¢…)
# =========================
def detect_intent(text: str) -> Optional[str]:
    open_keywords = ["ì—´", "ì—¬", "ì˜¬", "ê°œ", "ì˜¤í”ˆ"]
    close_keywords = ["ë‹«", "ì ", "ë‚´", "í´ë¡œì¦ˆ"]

    if any(k in text for k in open_keywords):
        return "OPEN_GATE"

    if any(k in text for k in close_keywords):
        return "CLOSE_GATE"

    return None


class WhisperSTT:
    """
    Whisper STT ìµœì¢…ë³¸ (í˜„ì—… ê¸°ì¤€)

    âœ” Windows ë§ˆì´í¬ ì…ë ¥ ì•ˆì •
    âœ” 48kHz â†’ 16kHz ë¦¬ìƒ˜í”Œë§
    âœ” ì˜ë¯¸ ì—†ëŠ” ë°œí™” ì œê±°
    âœ” Intent ì¤‘ì‹¬ ì²˜ë¦¬
    """

    def __init__(
        self,
        model_size: str = "base",
        device: Optional[int] = None,
        listen_seconds: float = 1.0,
    ):
        self.device = device
        self.listen_seconds = listen_seconds

        self.input_rate = 48000
        self.target_rate = 16000

        self.on_intent: Optional[Callable[[str, str], None]] = None
        self.model = get_whisper_model(model_size)

    def listen_once(self):
        frames = []

        def callback(indata, frames_count, time_info, status):
            frames.append(indata.copy())

        with sd.InputStream(
            samplerate=self.input_rate,
            device=self.device,
            channels=1,
            dtype="float32",
            callback=callback,
        ):
            time.sleep(self.listen_seconds)

        if not frames:
            return

        audio = np.concatenate(frames, axis=0).squeeze()

        # ğŸ”• ë¬´ìŒ ì»·
        if np.max(np.abs(audio)) < 0.02:
            return

        # ğŸ” 48k â†’ 16k
        audio = scipy.signal.resample_poly(
            audio,
            self.target_rate,
            self.input_rate,
        )

        # ğŸ”Š ì •ê·œí™”
        audio = audio.astype(np.float32)
        audio /= max(np.abs(audio).max(), 1e-6)

        result = self.model.transcribe(
            audio,
            language="ko",
            fp16=False,
            verbose=False,
            beam_size=1,
            best_of=1,
            temperature=0.0,
            condition_on_previous_text=False,
        )

        raw_text = normalize_text(result.get("text", ""))

        # âŒ ë„ˆë¬´ ì§§ì€ ë°œí™” ì œê±°
        if len(raw_text) <= 2:
            return

        # âŒ ë™ì‘ ë‹¨ì–´ ì—†ëŠ” ë°œí™” ì œê±°
        if not any(k in raw_text for k in ["ì—´", "ë‹«", "ì˜¬", "ë‚´"]):
            return

        print(f"ğŸ§ª RAW STT TEXT: {raw_text}")

        intent = detect_intent(raw_text)

        if intent:
            print(f"ğŸš¦ INTENT DETECTED: {intent}")
            if self.on_intent:
                self.on_intent(intent, raw_text)

    def start_listening(self):
        print("ğŸ™ Whisper STT ì‹œì‘ (Ctrl+C ì¢…ë£Œ)")
        try:
            while True:
                self.listen_once()
                time.sleep(0.25)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Whisper STT ì¢…ë£Œ")